{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dftDiCQg3vYy"
      },
      "source": [
        "# <font color='#4C5FDA'>**Breast Cancer Detection Based on CNNs Using Thermal Imaging** </font>\n",
        "\n",
        "Original paper by Juan Pablo Zuluaga, Zeina Al Masry, Khaled Benaggoune, Safa Meraghni & Noureddine Zerhouni: [A CNN-based methodology for breast cancer diagnosis using thermal images](https://www.tandfonline.com/doi/full/10.1080/21681163.2020.1824685)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title **Instalar paquetes necesarios**\n",
        "\n",
        "%%capture\n",
        "! pip install torchmetrics\n",
        "! pip install wandb -Uq\n",
        "! pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zEwblwS83vY1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgpintoruiz\u001b[0m (\u001b[33maiuis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title **Importamos librerías necesarias**\n",
        "\n",
        "# Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import cv2\n",
        "import os\n",
        "# import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps \n",
        "\n",
        "\n",
        "# Pytorch essentials\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyTorch torchvision\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "# Pytorch metrics\n",
        "from torchmetrics.classification import BinaryAccuracy, BinaryF1Score, BinaryRecall, BinaryPrecision\n",
        "\n",
        "# Pytorch essentials for datasets.\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "# wandb\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkrHeEps3vY3"
      },
      "source": [
        "## <font color='#ECA702'>**Configuración inicial para conectarnos con Kaggle**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJFg6k1x3vY5"
      },
      "source": [
        "1. Instalamos kaggle. Para poder usar comandos de Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwqionQb3vY6",
        "outputId": "3d70fa3f-25b6-4998-b692-95839cca329e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP3nl2Et3vY7"
      },
      "source": [
        "Subimos nuestro token de autenticación de Kaggle (si estamos en colab, sino colocarlo en la carpeta del proyecto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARP6wZsb3vY8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0VPkGso3vY9"
      },
      "source": [
        "1. Creamos los directorios de Kaggle\n",
        "2. Copiamos nuestro token en .kaggle\n",
        "3. Con `chmod 600` establecemos los permitos del token en 600, es decir, que solo yo tengo permisos de lectura y escritura sobre el archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ed2nCVTu3vY-"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UhQ_SI9x3vZA"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGkGIazz3vZB"
      },
      "source": [
        "## <font color='#ECA702'>**Procesamiento del dataset**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15sRg8fW3vZC"
      },
      "source": [
        "### <font color='#52F17F'>**Carga del dataset**</font>\n",
        "\n",
        "Traemos el dataset [Thermal Images for Breast Cancer Diagnosis DMR-IR](https://www.kaggle.com/datasets/asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir) desde kaggle.\n",
        "\n",
        "This dataset is a methodology for breast disease computer-aided diagnosis using dynamic thermography. The thermal images for breast tumors are classified according to DMR-IR standards.\n",
        "\n",
        "Two types of tumors are classified in this dataset one is benign another is malignant.\n",
        "- Benign: This type of tumor is usually well-defined and round or oval in shape. (non-cancerous tumor)\n",
        "- Malignant: This type of tumor is usually poorly defined and irregular with lobules. (cancerous tumor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lmT0aOvG3vZD"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir\n",
        "! unzip thermal-images-for-breast-cancer-diagnosis-dmrir.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QToIa8zB3vZE"
      },
      "source": [
        "Después de descargar los datos. Debemos entender la estructura de las carpetas para poder trabajar con ellas de una mejor manera.\n",
        "1. La carpeta principal `Imagens e Matrizes da Tese de Thiago Alves Elias da Silva` son todos los datos `data`.\n",
        "2. La carpeta `12 Novos Casos de Testes` la podemos tomar como nuestro conjunto de prueba (`test`).\n",
        "3. Mientras que la carpeta `Desenvolvimento da Metodologia` será nuestro conjunto de entrenamiento (`train`).\n",
        "\n",
        "Luego dentro de nuestras carpetas de `train` y `test` encontramos dos categorías `DOENTES`y `SAUDAтХа├╝VEIS` o SAUDÁVEI. Los primeros son los casos malignos y los segundos benignos.\n",
        "\n",
        "Dentro de cada una de las carpetas de pacientes saludables y enfermos se encuentran carpetas con números, cada número representa un paciente. Y para cada paciente tendremos dos carpetas más, una para las imágenes **segmentadas** en escala de grises y la otra para la matrix o mapa de calor.\n",
        "\n",
        "Algo bueno de este dataset es que ya está dividido por pacientes, es decir, no tendremos imagenes del mismo paciente en el conjunto de entrenamiento y testeo. Por lo tanto, vamos a entrenar con N pacientes, y testear con K pacientes, que no son los mismos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='#52F17F'>**Creación del DataFrame Pandas auxiliar**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>segmented_image</th>\n",
              "      <th>matrix</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>patient</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>Imagens e Matrizes da Tese de Thiago Alves Eli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           segmented_image  \\\n",
              "patient                                                      \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...   \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...   \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...   \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...   \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...   \n",
              "\n",
              "                                                    matrix  label  \n",
              "patient                                                            \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...      0  \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...      0  \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...      0  \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...      0  \n",
              "14       Imagens e Matrizes da Tese de Thiago Alves Eli...      0  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TEST_PATH = \"Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/12 Novos Casos de Testes\"\n",
        "TRAIN_PATH = \"Imagens e Matrizes da Tese de Thiago Alves Elias da Silva/Desenvolvimento da Metodologia\"\n",
        "\n",
        "patients = []\n",
        "labels = []\n",
        "segmented_images = []\n",
        "matrices = []\n",
        "\n",
        "\"\"\"\n",
        "Esta construcción del dataset depende de la estructura del mismo\n",
        "\"\"\"\n",
        "\n",
        "# Primero consigo la ruta de imagenes y matrices para cada uno de los pacientes\n",
        "\n",
        "for category in os.listdir(TEST_PATH):\n",
        "  # print(category)\n",
        "  for patient in os.listdir(os.path.join(TEST_PATH, category)):\n",
        "    patient_path = os.path.join(TEST_PATH, category, patient)\n",
        "    # print(patient_path)\n",
        "    for record in os.listdir(f'{patient_path}/Segmentadas'):\n",
        "      record_path = os.path.join(f'{patient_path}/Segmentadas', record)\n",
        "      # print(record_path)\n",
        "      segmented_images.append(record_path)\n",
        "      if '-dir.png' in record_path:\n",
        "        matrix_path = os.path.join(record_path.replace('Segmentadas','Matrizes').replace(\"-dir.png\", \".txt\"))\n",
        "      elif '-esq.png' in record_path:\n",
        "        matrix_path = os.path.join(record_path.replace('Segmentadas','Matrizes').replace(\"-esq.png\", \".txt\"))\n",
        "      # print(matrix_path)\n",
        "      if os.path.exists(matrix_path):\n",
        "        matrices.append(matrix_path)\n",
        "      else:\n",
        "        good_part, bad_part = matrix_path[:len(matrix_path)//2], matrix_path[len(matrix_path)//2:]\n",
        "        bad_part = bad_part.replace('Matrizes', 'Matrizes de Temperatura')\n",
        "        matrix_path = good_part+bad_part\n",
        "        matrices.append(matrix_path)\n",
        "        # print(matrix_path)\n",
        "\n",
        "      label = patient_path.split('/')[2]\n",
        "      if label == 'DOENTES':\n",
        "        label = 1\n",
        "      else:\n",
        "        label = 0\n",
        "      labels.append(label)\n",
        "      patients.append(record.split('_')[1])\n",
        "\n",
        "for category in os.listdir(TRAIN_PATH):\n",
        "  # print(category)\n",
        "  for patient in os.listdir(os.path.join(TRAIN_PATH, category)):\n",
        "    patient_path = os.path.join(TRAIN_PATH, category, patient)\n",
        "    for record in os.listdir(f'{patient_path}/Segmentadas'):\n",
        "      record_path = os.path.join(f'{patient_path}/Segmentadas', record)\n",
        "      # print(record_path)\n",
        "      segmented_images.append(record_path)\n",
        "      if '-dir.png' in record_path:\n",
        "        matrix_path = os.path.join(record_path.replace('Segmentadas','Matrizes').replace(\"-dir.png\", \".txt\"))\n",
        "      elif '-esq.png' in record_path:\n",
        "        matrix_path = os.path.join(record_path.replace('Segmentadas','Matrizes').replace(\"-esq.png\", \".txt\"))\n",
        "      # print(matrix_path)\n",
        "      if os.path.exists(matrix_path):\n",
        "        matrices.append(matrix_path)\n",
        "      else:\n",
        "        good_part, bad_part = matrix_path[:len(matrix_path)//2], matrix_path[len(matrix_path)//2:]\n",
        "        bad_part = bad_part.replace('Matrizes', 'Matrizes de Temperatura')\n",
        "        matrix_path = good_part+bad_part\n",
        "        matrices.append(matrix_path)\n",
        "        # print(matrix_path)\n",
        "\n",
        "      label = patient_path.split('/')[2]\n",
        "      if label == 'DOENTES':\n",
        "        label = 1\n",
        "      else:\n",
        "        label = 0\n",
        "      labels.append(label)\n",
        "      patients.append(record.split('_')[1])\n",
        "  \n",
        "# Crear un DataFrame con la información\n",
        "data = pd.DataFrame({\n",
        "    'patient': patients,\n",
        "    'segmented_image': segmented_images,\n",
        "    'matrix': matrices,\n",
        "    'label': labels\n",
        "})\n",
        "\n",
        "data.set_index('patient', inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.to_csv(\"data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyk9P3bb3vZU"
      },
      "source": [
        "### <font color='#52F17F'>**Creación del Dataset PyTorch**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Constante encontrada al iterar por todas las imágenes segmentadas, \n",
        "calcular su valor máximo de temperatura y devolver el máximo de todas.\n",
        "\"\"\"\n",
        "\n",
        "MAX_TEMPERATURE = 36.44"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "-RN_VmlV3vZV"
      },
      "outputs": [],
      "source": [
        "class ThermalDataset(Dataset):\n",
        "  def __init__(self, dataframe, transform = None, normalize = None):\n",
        "    self.dataframe = dataframe\n",
        "    self.normalize = normalize\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataframe)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    \"\"\" Carga de la imagen \"\"\"\n",
        "\n",
        "    # Entramos a la carpeta y conseguimos la imagen de la lista\n",
        "    img_path = self.dataframe['segmented_image'][index]\n",
        "\n",
        "    # Leemos la imagen segmentada en escala de grises\n",
        "    img = Image.open(img_path)\n",
        "    img = ImageOps.grayscale(img)\n",
        "    img = np.array(img)\n",
        "\n",
        "    \"\"\" Carga de la matrix \"\"\"\n",
        "    \n",
        "    matrix_path = self.dataframe['matrix'][index]\n",
        "    # print(matrix_path)\n",
        "      \n",
        "    matrix = np.loadtxt(matrix_path, dtype=np.float32) # https://www.geeksforgeeks.org/import-text-files-into-numpy-arrays/\n",
        "\n",
        "    \"\"\" Consigo la imagen segmentada con los valores de la matrix \"\"\"\n",
        "\n",
        "    segmented = np.where(img==0, 0, 1) # int64\n",
        "    # segmented = img * matrix\n",
        "    img = (matrix * segmented).astype(np.float32) # float32, shape (480, 640)\n",
        "\n",
        "    # Le agrego un canal explícito \n",
        "    img = np.expand_dims(img, axis=2) # https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html\n",
        "\n",
        "    if self.normalize:\n",
        "      img /= MAX_TEMPERATURE\n",
        "\n",
        "    \"\"\" Consiguiendo el label \"\"\"\n",
        "\n",
        "    label = self.dataframe['label'][index]\n",
        "\n",
        "    \"\"\" Convertir las imagenes en tensores y hacer resize \"\"\"\n",
        "    if self.transform:\n",
        "      # Aplicamos las transformaciones a la imagen\n",
        "      # print(type(img), img.shape)\n",
        "      img = self.transform(img)\n",
        "      \n",
        "    return img, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPz3tqLJ3vZY"
      },
      "source": [
        "En teoría por cada paciente tenemos 20 imagenes, pero las cuentas no cuadran, por ejemplo en testeo deberíamos tener 9x20 = 180 imagenes, pero aparecen 240. Esto sucede debido a que hay algunas imagenes que están separadas en la parte izquierda y derecha.\n",
        "\n",
        "Para el conjunto de entrenamiento tampoco cuadra el número de matrices. Esto es debido a que algunos pacientes tienen una matriz que se llama `ESTATICO` que no tengo ni idea para qué es pero no es problema ya que no hace 'match' con ninguna imágen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H4PvzY2RS6Tc"
      },
      "outputs": [],
      "source": [
        "# Todas las imagenes vienen en h: 480, w: 640. El objetivo es disminuir el tamaño\n",
        "# sin perder la relación de aspecto. https://gist.github.com/tomvon/ae288482869b495201a0\n",
        "\n",
        "HEIGHT = 300\n",
        "r = HEIGHT/480 # Calculo la relación de aspecto. \n",
        "WIDTH = int(640*r)\n",
        "# print(f\"Las imagenes son reescaladas a {HEIGHT}x{WIDTH}\")\n",
        "\n",
        "# https://pytorch.org/vision/main/transforms.html#performance-considerations\n",
        "transform = v2.Compose([  \n",
        "    v2.ToImage(), \n",
        "    # v2.Resize(size=(HEIGHT, WIDTH), antialias=True), \n",
        "    # v2.ToDtype(torch.float32),\n",
        "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1522\n",
            "torch.Size([1, 480, 640]) 1\n"
          ]
        }
      ],
      "source": [
        "complete_dataset = ThermalDataset(data, transform=transform)\n",
        "print(complete_dataset.__len__())\n",
        "print(complete_dataset[1180][0].shape, complete_dataset[1180][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='#52F17F'>**Partición de los datos**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extraer los datos para GroupKFold https://discuss.pytorch.org/t/custom-datatype-for-many-images-to-one-label/87629\n",
        "X = [i for i in range(len(data))]\n",
        "y = data['label'].values\n",
        "groups = data.index.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "División 1:\n",
            "  Pacientes en entrenamiento: ['03' '05' '06' '07' '08' '11' '13' '14' '16' '17' '24' '25' '26' '27'\n",
            " '28' '29' '31' '32' '35' '36' '37' '38' '39' '40' '42' '43' '44' '46'\n",
            " '48' '51' '52' '53' '55' '56' '58' '60' '61' '62' '64' '65' '66' '69']\n",
            "  Pacientes en prueba: ['00' '01' '02' '04' '09' '15' '30' '34' '41' '45' '49' '54' '59' '63']\n",
            "  Número de pacientes en entrenamiento: 42\n",
            "  Número de pacientes en prueba: 14\n",
            "División 2:\n",
            "  Pacientes en entrenamiento: ['00' '01' '02' '04' '05' '07' '08' '09' '11' '14' '15' '16' '17' '24'\n",
            " '26' '27' '28' '30' '31' '32' '34' '35' '36' '37' '39' '40' '41' '43'\n",
            " '44' '45' '48' '49' '51' '52' '54' '55' '59' '60' '61' '63' '64' '65']\n",
            "  Pacientes en prueba: ['03' '06' '13' '25' '29' '38' '42' '46' '53' '56' '58' '62' '66' '69']\n",
            "  Número de pacientes en entrenamiento: 42\n",
            "  Número de pacientes en prueba: 14\n",
            "División 3:\n",
            "  Pacientes en entrenamiento: ['00' '01' '02' '03' '04' '05' '06' '08' '09' '13' '14' '15' '25' '26'\n",
            " '29' '30' '31' '32' '34' '36' '37' '38' '40' '41' '42' '44' '45' '46'\n",
            " '48' '49' '51' '53' '54' '56' '58' '59' '60' '62' '63' '64' '66' '69']\n",
            "  Pacientes en prueba: ['07' '11' '16' '17' '24' '27' '28' '35' '39' '43' '52' '55' '61' '65']\n",
            "  Número de pacientes en entrenamiento: 42\n",
            "  Número de pacientes en prueba: 14\n",
            "División 4:\n",
            "  Pacientes en entrenamiento: ['00' '01' '02' '03' '04' '06' '07' '09' '11' '13' '15' '16' '17' '24'\n",
            " '25' '27' '28' '29' '30' '34' '35' '38' '39' '41' '42' '43' '45' '46'\n",
            " '49' '52' '53' '54' '55' '56' '58' '59' '61' '62' '63' '65' '66' '69']\n",
            "  Pacientes en prueba: ['05' '08' '14' '26' '31' '32' '36' '37' '40' '44' '48' '51' '60' '64']\n",
            "  Número de pacientes en entrenamiento: 42\n",
            "  Número de pacientes en prueba: 14\n"
          ]
        }
      ],
      "source": [
        "groupk_folds = 4\n",
        "gkf = GroupKFold(n_splits=groupk_folds)\n",
        "# Realizar la validación cruzada por grupos\n",
        "for i, (train_index, test_index) in enumerate(gkf.split(X, y, groups), 1):\n",
        "    train_groups = groups[train_index]\n",
        "    test_groups = groups[test_index]\n",
        "\n",
        "    print(f\"División {i}:\")\n",
        "    print(\"  Pacientes en entrenamiento:\", np.unique(train_groups))\n",
        "    print(\"  Pacientes en prueba:\", np.unique(test_groups))\n",
        "    print(\"  Número de pacientes en entrenamiento:\", len(np.unique(train_groups)))\n",
        "    print(\"  Número de pacientes en prueba:\", len(np.unique(test_groups)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='#52F17F'>**Make's for wandb**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data(train_index, test_index, data):\n",
        "    full_dataset = ThermalDataset(data, transform=transform)\n",
        "\n",
        "    train_subset = torch.utils.data.Subset(full_dataset, train_index)\n",
        "    test_subset = torch.utils.data.Subset(full_dataset, test_index)\n",
        "\n",
        "    return train_subset, test_subset\n",
        "\n",
        "\n",
        "def make_loader(dataset, batch_size):\n",
        "    loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                         batch_size=batch_size,\n",
        "                                         shuffle=True,\n",
        "                                         pin_memory=True, num_workers=2)\n",
        "    return loader\n",
        "\n",
        "def build_optimizer(network, optimizer, learning_rate):\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = torch.optim.SGD(network.parameters(),\n",
        "                              lr=learning_rate, momentum=0.9)\n",
        "    elif optimizer == \"adam\":\n",
        "        optimizer = torch.optim.Adam(network.parameters(),\n",
        "                               lr=learning_rate)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikyFIUY1NrXi"
      },
      "source": [
        "## <font color='#ECA702'>**Modelo CNN**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='#52F17F'>**Creando el modelo**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zvkND1_OKHxu"
      },
      "outputs": [],
      "source": [
        "# Conventional and convolutional neural network\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, kernels, classes=1, input_size=[1, 480, 640]):\n",
        "        super(ConvNet, self).__init__()\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(kernels[0], kernels[1], kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7 * 7 * kernels[-1], classes)\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.kernels = kernels\n",
        "\n",
        "        self.final_feature_size = self.calculate_final_feature_size()\n",
        "        # Adjust the fully connected layer to use the final feature size\n",
        "        self.fc = nn.Linear(self.final_feature_size, classes)\n",
        "\n",
        "    def calculate_final_feature_size(self):\n",
        "        size_h, size_w = self.input_size[1:]\n",
        "        size_h = self.conv_output_size(size_h, 5, 1, 2) // 2  # layer1 height\n",
        "        size_w = self.conv_output_size(size_w, 5, 1, 2) // 2  # layer1 width\n",
        "\n",
        "        size_h = self.conv_output_size(size_h, 5, 1, 2) // 2  # layer2 height\n",
        "        size_w = self.conv_output_size(size_w, 5, 1, 2) // 2  # layer2 width\n",
        "\n",
        "        return size_h * size_w * self.kernels[-1]\n",
        "\n",
        "    def conv_output_size(self, size, kernel_size, stride, padding):\n",
        "        return (size - kernel_size + 2 * padding) // stride + 1\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrada: (torch.Size([1, 1, 480, 640]), {torch.float32})\n",
            "Salida: (torch.Size([1, 1]), torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# Test al modelo, para ver si nos entrega la salida esperada\n",
        "\n",
        "input_image = complete_dataset[0][0].unsqueeze(0)\n",
        "print(f\"Entrada: {input_image.size(), {input_image.dtype}}\")\n",
        "model = ConvNet(kernels=[32, 64])\n",
        "ouput = model(input_image)\n",
        "print(f\"Salida: {ouput.size(), ouput.dtype}\") # Esperado: [1, 2] (batch 1, 2 clases)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='#52F17F'>**Entrenamiento del modelo**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "An27UN3oKbAB"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def make(config, train_index, test_index, data):\n",
        "    # Make the data\n",
        "    train, test = get_data(train_index, test_index, data)\n",
        "    train_loader = make_loader(train, batch_size=config.batch_size)\n",
        "    test_loader = make_loader(test, batch_size=config.batch_size)\n",
        "\n",
        "    # Make the model\n",
        "    model = ConvNet(kernels=config.features, classes=config.classes).to(DEVICE)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = build_optimizer(model, config.optimizer, config.learning_rate)\n",
        "\n",
        "    # N-epochs to train\n",
        "    epochs = config.epochs\n",
        "\n",
        "    # Make metrics\n",
        "    accuracy_fn = BinaryAccuracy().to(DEVICE)\n",
        "    f1_score_fn = BinaryF1Score().to(DEVICE)\n",
        "    recall_fn = BinaryRecall().to(DEVICE)\n",
        "    precision_fn = BinaryPrecision().to(DEVICE)\n",
        "\n",
        "    return model, train_loader, test_loader, criterion, optimizer, accuracy_fn, f1_score_fn, recall_fn, precision_fn, epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='##6600CC'>**Training loop**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_log(loss, accuracy, step, current):\n",
        "    \"\"\" Log the metrics for the current batch into wandb\n",
        "\n",
        "    Args:\n",
        "        loss: the value of the loss at current batch\n",
        "        accuracy: the value of the accuracy at current batch\n",
        "        step: actual step\n",
        "        current: actual batch\n",
        "    \"\"\"\n",
        "\n",
        "    # Where the magic happens\n",
        "    # wandb.log({\"step\":step, \"loss\": loss, \"accuracy\": accuracy}, step=step)\n",
        "    wandb.log({\"step\":step, \"train_loss\": loss, \"train_accuracy\": accuracy})\n",
        "    print(f\"train loss: {loss:.3f} accuracy: {accuracy:.3f} [after {current} batches]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_batch(images, labels, model, optimizer, criterion, metrics_fn):\n",
        "    \"\"\"Train the model on a single bacth of the dataloader.\n",
        "\n",
        "    Args:\n",
        "        dataloader: an instance of `torch.utils.data.DataLoader`, containing the training data.\n",
        "        model: an instance of `torch.nn.Module`, the model to be trained.\n",
        "        optimizer: an instance of `torch.optim.Optimizer`, the optimizer used for training.\n",
        "        criterion: a callable, the loss function.\n",
        "        metrics_fn: a callable, the metrics function.\n",
        "\n",
        "    Returns:\n",
        "        loss: the value of the loss at current batch\n",
        "        accuracy: the value of the accuracy at current batch\n",
        "    \"\"\"\n",
        "\n",
        "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "    # Forward pass ➡\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels.unsqueeze(1).float())\n",
        "    accuracy = metrics_fn(outputs, labels.unsqueeze(1).float())\n",
        "\n",
        "    # Backward pass ⬅\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Step with optimizer\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, loader, criterion, optimizer, metric_fn, step):\n",
        "\n",
        "    model.train()\n",
        "    n_prints = int(len(loader)/4)\n",
        "\n",
        "    # Run training and track with wandb\n",
        "    for batch, (images, labels) in enumerate(loader):\n",
        "\n",
        "        loss, accuracy = train_batch(images, labels, model, optimizer, criterion, metric_fn)\n",
        "\n",
        "        # Report metrics every n_prints batch\n",
        "        if batch % n_prints == n_prints-1:\n",
        "            loss, current = loss.item(), batch\n",
        "            # print(step)\n",
        "            train_log(loss, accuracy, step, current)\n",
        "            # Increment the step after logging\n",
        "            step += 1\n",
        "    return step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <font color='##6600CC'>**Evaluation loop**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(model, test_loader, loss_fn, accuracy_fn, f1_score_fn, recall_fn, precision_fn, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    num_batches = len(test_loader)\n",
        "    val_loss, val_accuracy, val_f1, val_recall, val_precision = 0, 0, 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            val_loss += loss_fn(outputs, labels.unsqueeze(1).float()).item()\n",
        "            val_accuracy += accuracy_fn(outputs, labels.unsqueeze(1).float())\n",
        "            val_f1 += f1_score_fn(outputs, labels.unsqueeze(1).float())\n",
        "            val_recall += recall_fn(outputs, labels.unsqueeze(1).float())\n",
        "            val_precision += precision_fn(outputs, labels.unsqueeze(1).float())\n",
        "\n",
        "    val_loss /= num_batches\n",
        "    val_accuracy /= num_batches\n",
        "    val_f1 /= num_batches\n",
        "    val_recall /= num_batches\n",
        "    val_precision /= num_batches\n",
        "\n",
        "    # Log the evaluation metrics at the end of batches\n",
        "    wandb.log({\"epoch\": epoch+1, \"val_loss\": val_loss, \"val_accuracy\": val_accuracy, \"val_f1\": val_f1, \"val_recall\": val_recall, \"val_precision\": val_precision})\n",
        "    print(f\"val loss: {val_loss:.3f} accuracy: {val_accuracy:.3f} [after {num_batches} batches]\")\n",
        "    return images, val_accuracy, val_f1, val_recall, val_precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='#52F17F'>**Train and watch your metrics on wandb.ai**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "if os.path.exists('../models') == False:\n",
        "  os.mkdir(\"../models\")\n",
        "MODELS_DIR = \"../models\"\n",
        "\n",
        "\n",
        "def model_pipeline(num, sweep_id, sweep_run_name, hyperparameters, train_index, test_index, data):\n",
        "\n",
        "    # tell wandb to get started\n",
        "    run_name = f'{sweep_run_name}--{num}'\n",
        "    with wandb.init(config=hyperparameters, dir=MODELS_DIR\n",
        "                    , group=sweep_id, job_type=sweep_run_name, name=run_name, reinit=True):\n",
        "      # access all HPs through wandb.config, so logging matches execution!\n",
        "      config = wandb.config\n",
        "\n",
        "      # make the model, data, and optimization problem\n",
        "      model, train_loader, test_loader, criterion, optimizer, accuracy_fn, f1_score_fn, recall_fn, precision_fn, epochs = make(config,\n",
        "                                                                                                                                train_index,\n",
        "                                                                                                                                test_index,\n",
        "                                                                                                                                data)\n",
        "      print(model)\n",
        "\n",
        "      # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "      wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "      # and use them to train the model\n",
        "\n",
        "      # Initialize the step counter\n",
        "      step = 0\n",
        "      best_val_accuracy = float('inf')\n",
        "      patience = 10\n",
        "\n",
        "      print(f'FOLD {num+1}')\n",
        "      print('--------------------------------')\n",
        "\n",
        "      # Estas métricas son el promedio luego de todas las épocas que alcance a tomar el modelo\n",
        "      avg_val_accuracy_epochs, avg_val_recall_epochs, avg_val_precision_epochs, avg_val_f1_score_epochs = 0, 0, 0, 0\n",
        "\n",
        "      for t in range(epochs):\n",
        "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "        step = train(model, train_loader, criterion, optimizer, accuracy_fn, step=step)\n",
        "        # and test its performance per epoch\n",
        "        images, val_accuracy, val_f1, val_recall, val_precision = test(model, test_loader, criterion, accuracy_fn, f1_score_fn, recall_fn, precision_fn, epoch=t)\n",
        "\n",
        "        avg_val_accuracy_epochs += val_accuracy\n",
        "        avg_val_recall_epochs += val_recall\n",
        "        avg_val_precision_epochs += val_precision\n",
        "        avg_val_f1_score_epochs += val_f1\n",
        "\n",
        "        # Early stopping\n",
        "        if val_accuracy < best_val_accuracy:\n",
        "          best_val_accuracy = val_accuracy\n",
        "          patience = 10  # Reset patience counter\n",
        "        else:\n",
        "          patience -= 1\n",
        "          if patience == 0:\n",
        "              break\n",
        "          \n",
        "      avg_val_accuracy_epochs /= (t+1)\n",
        "      avg_val_f1_score_epochs /= (t+1)\n",
        "      avg_val_recall_epochs /= (t+1)\n",
        "      avg_val_precision_epochs /= (t+1)\n",
        "      \n",
        "      # Save the model in the exchangeable ONNX format\n",
        "      torch.onnx.export(model, images,\"model.onnx\")\n",
        "      wandb.save(\"model.onnx\")\n",
        "      wandb.finish()\n",
        "\n",
        "    return avg_val_accuracy_epochs, avg_val_f1_score_epochs, avg_val_recall_epochs, avg_val_precision_epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reset_wandb_env():\n",
        "    exclude = {\n",
        "        \"WANDB_PROJECT\",\n",
        "        \"WANDB_ENTITY\",\n",
        "        \"WANDB_API_KEY\",\n",
        "    }\n",
        "    for key in os.environ.keys():\n",
        "        if key.startswith(\"WANDB_\") and key not in exclude:\n",
        "            del os.environ[key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_validate():\n",
        "    num_folds = 4\n",
        "    gkf = GroupKFold(n_splits=num_folds)\n",
        "\n",
        "    # Extraer los datos para GroupKFold https://discuss.pytorch.org/t/custom-datatype-for-many-images-to-one-label/87629\n",
        "    X = [i for i in range(len(data))]\n",
        "    y = data['label'].values\n",
        "    groups = data.index.values\n",
        "\n",
        "\n",
        "    sweep_run = wandb.init(dir=MODELS_DIR)\n",
        "    sweep_id = sweep_run.sweep_id or \"unknown\"\n",
        "    sweep_url = sweep_run.get_sweep_url()\n",
        "    project_url = sweep_run.get_project_url()\n",
        "    sweep_group_url = f'{project_url}/groups/{sweep_id}'\n",
        "    sweep_run.notes = sweep_group_url\n",
        "    sweep_run.save()\n",
        "    sweep_run_name = sweep_run.name or sweep_run.id or \"unknown_2\"\n",
        "    sweep_run_id = sweep_run.id\n",
        "    sweep_run.finish()\n",
        "    wandb.sdk.wandb_setup._setup(_reset=True)\n",
        "\n",
        "    metrics = {\n",
        "        \"val_accuracy\": [],\n",
        "        \"val_recall\": [],\n",
        "        \"val_precision\": [],\n",
        "        \"val_f1_score\": []\n",
        "    }\n",
        "    for fold, (train_ids, test_ids) in enumerate(gkf.split(X, y, groups)):\n",
        "\n",
        "\n",
        "        reset_wandb_env()\n",
        "\n",
        "        # Entreno y valido cada run pasandole el sweep y la config\n",
        "        val_accuracy, val_f1, val_recall, val_precision = model_pipeline(\n",
        "            sweep_id=sweep_id, num=fold,\n",
        "            sweep_run_name=sweep_run_name,\n",
        "            hyperparameters=dict(sweep_run.config),\n",
        "            train_index=train_ids,\n",
        "            test_index=test_ids,\n",
        "            data=data\n",
        "        )\n",
        "        metrics[\"val_accuracy\"].append(val_accuracy)\n",
        "        metrics[\"val_recall\"].append(val_f1)\n",
        "        metrics[\"val_precision\"].append(val_recall)\n",
        "        metrics[\"val_f1_score\"].append(val_precision)\n",
        "\n",
        "    # resume the sweep run\n",
        "    sweep_run = wandb.init(id=sweep_run_id, resume=\"must\", dir=MODELS_DIR)\n",
        "\n",
        "    # Calcula los promedios de cada métrica\n",
        "    avg_val_accuracy = sum(metrics[\"val_accuracy\"]) / len(metrics[\"val_accuracy\"])\n",
        "    avg_val_recall = sum(metrics[\"val_recall\"]) / len(metrics[\"val_recall\"])\n",
        "    avg_val_precision = sum(metrics[\"val_precision\"]) / len(metrics[\"val_precision\"])\n",
        "    avg_val_f1_score = sum(metrics[\"val_f1_score\"]) / len(metrics[\"val_f1_score\"])\n",
        "    # Log metrics to sweep run\n",
        "    sweep_run.log({\n",
        "        \"val_accuracy\": avg_val_accuracy,\n",
        "        \"val_recall\": avg_val_recall,\n",
        "        \"val_precision\": avg_val_precision,\n",
        "        \"val_f1\": avg_val_f1_score\n",
        "    })\n",
        "    sweep_run.finish()\n",
        "\n",
        "    print(\"*\" * 40)\n",
        "    print(\"Sweep URL:       \", sweep_url)\n",
        "    print(\"Sweep Group URL: \", sweep_group_url)\n",
        "    print(\"*\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <font color='#52F17F'>**Configuración de busqueda de hiperparametros**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "sweep_configuration = {\n",
        "    'method': 'random',\n",
        "    'name': 'sweep-test-1',\n",
        "    'metric': {\n",
        "        'goal': 'maximize',\n",
        "        'name': 'val_accuracy'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {'value': 50},\n",
        "        'classes': {'value': 1},\n",
        "        'features': {'values': [[8, 16], [16, 32]]},\n",
        "        'batch_size': {'values': [16, 32, 64]},\n",
        "        'learning_rate': {'values': [0.01, 0.001, 0.0001]},\n",
        "        'optimizer': {'values': ['adam', 'sgd']},\n",
        "        'dataset': {'value': 'ThermalBreastCancer'},\n",
        "        'architecture': {'value': 'CNN'}\n",
        "    },\n",
        "    # 'early_terminate': {\n",
        "    #     'type': 'hyperband',\n",
        "    #     'eta': 2,\n",
        "    #     'min_iter':2\n",
        "    #  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: yi65n01e\n",
            "Sweep URL: https://wandb.ai/aiuis/dip-project/sweeps/yi65n01e\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_configuration, project='dip-project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9sdvte8b with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclasses: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: ParkinsonVideo\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeatures: [16, 32]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_105515-9sdvte8b</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/9sdvte8b' target=\"_blank\">efficient-sweep-4</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92' target=\"_blank\">https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92' target=\"_blank\">https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/9sdvte8b' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/9sdvte8b</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">efficient-sweep-4</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/9sdvte8b' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/9sdvte8b</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_105515-9sdvte8b/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_105525-6oet5feu</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/6oet5feu' target=\"_blank\">efficient-sweep-4--0</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/6oet5feu' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/6oet5feu</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=614400, out_features=1, bias=True)\n",
            ")\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_4448/1545842686.py\", line 39, in model_pipeline\n",
            "    step = train(model, train_loader, criterion, optimizer, accuracy_fn, step=step)\n",
            "  File \"/tmp/ipykernel_4448/1618031750.py\", line 9, in train\n",
            "    loss, accuracy = train_batch(images, labels, model, optimizer, criterion, metric_fn)\n",
            "  File \"/tmp/ipykernel_4448/2864932988.py\", line 25, in train_batch\n",
            "    loss.backward()\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/_tensor.py\", line 525, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 600.00 MiB. GPU \n"
          ]
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">efficient-sweep-4--0</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/6oet5feu' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/6oet5feu</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_105525-6oet5feu/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Run 9sdvte8b errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
            "    self._function()\n",
            "  File \"/tmp/ipykernel_4448/2188155363.py\", line 35, in cross_validate\n",
            "    val_accuracy, val_f1, val_recall, val_precision = model_pipeline(\n",
            "  File \"/tmp/ipykernel_4448/1545842686.py\", line 39, in model_pipeline\n",
            "    step = train(model, train_loader, criterion, optimizer, accuracy_fn, step=step)\n",
            "  File \"/tmp/ipykernel_4448/1618031750.py\", line 9, in train\n",
            "    loss, accuracy = train_batch(images, labels, model, optimizer, criterion, metric_fn)\n",
            "  File \"/tmp/ipykernel_4448/2864932988.py\", line 25, in train_batch\n",
            "    loss.backward()\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/_tensor.py\", line 525, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
            "    _engine_run_backward(\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
            "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 600.00 MiB. GPU \n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 9sdvte8b errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_4448/2188155363.py\", line 35, in cross_validate\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     val_accuracy, val_f1, val_recall, val_precision = model_pipeline(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_4448/1545842686.py\", line 39, in model_pipeline\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     step = train(model, train_loader, criterion, optimizer, accuracy_fn, step=step)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_4448/1618031750.py\", line 9, in train\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss, accuracy = train_batch(images, labels, model, optimizer, criterion, metric_fn)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_4448/2864932988.py\", line 25, in train_batch\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss.backward()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/_tensor.py\", line 525, in backward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch.autograd.backward(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 267, in backward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _engine_run_backward(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 600.00 MiB. GPU \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tynhn87r with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclasses: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: ParkinsonVideo\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeatures: [8, 16]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_105540-tynhn87r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/tynhn87r' target=\"_blank\">lively-sweep-5</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92' target=\"_blank\">https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92' target=\"_blank\">https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/tynhn87r' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/tynhn87r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lively-sweep-5</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/tynhn87r' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/tynhn87r</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_105540-tynhn87r/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_105551-aenrdp82</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/aenrdp82' target=\"_blank\">lively-sweep-5--0</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/aenrdp82' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/aenrdp82</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=307200, out_features=1, bias=True)\n",
            ")\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.804 accuracy: 0.688 [after 17 batches]\n",
            "train loss: 0.183 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.213 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.113 accuracy: 1.000 [after 71 batches]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss: 0.963 accuracy: 0.526 [after 24 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.130 accuracy: 0.938 [after 17 batches]\n",
            "train loss: 0.015 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.010 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 1.515 accuracy: 0.510 [after 24 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.010 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.037 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.004 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 1.832 accuracy: 0.518 [after 24 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.005 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.003 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.324 accuracy: 0.526 [after 24 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.665 accuracy: 0.529 [after 24 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.001 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.835 accuracy: 0.537 [after 24 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.998 accuracy: 0.538 [after 24 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 3.142 accuracy: 0.546 [after 24 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 3.270 accuracy: 0.550 [after 24 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 3.275 accuracy: 0.562 [after 24 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.001 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 3.383 accuracy: 0.565 [after 24 batches]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 3.498 accuracy: 0.566 [after 24 batches]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁███▇███████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▃▁▂▃▃▄▄▆▆███</td></tr><tr><td>val_f1</td><td>▂▁▁▄▄▅▅▅▅▆██</td></tr><tr><td>val_loss</td><td>▁▃▃▅▆▆▇▇▇▇██</td></tr><tr><td>val_precision</td><td>▄▁▂▁▂▄▃▂▄▄▇█</td></tr><tr><td>val_recall</td><td>▂▂▁▆▅▆▅▅▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>12</td></tr><tr><td>step</td><td>47</td></tr><tr><td>train_accuracy</td><td>1.0</td></tr><tr><td>train_loss</td><td>0.0</td></tr><tr><td>val_accuracy</td><td>0.56585</td></tr><tr><td>val_f1</td><td>0.57722</td></tr><tr><td>val_loss</td><td>3.49788</td></tr><tr><td>val_precision</td><td>0.67586</td></tr><tr><td>val_recall</td><td>0.53026</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lively-sweep-5--0</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/aenrdp82' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/aenrdp82</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_105551-aenrdp82/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_105951-gaxdeh84</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/gaxdeh84' target=\"_blank\">lively-sweep-5--1</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/gaxdeh84' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/gaxdeh84</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=307200, out_features=1, bias=True)\n",
            ")\n",
            "FOLD 2\n",
            "--------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.498 accuracy: 0.750 [after 17 batches]\n",
            "train loss: 0.296 accuracy: 0.938 [after 35 batches]\n",
            "train loss: 0.225 accuracy: 0.938 [after 53 batches]\n",
            "train loss: 0.072 accuracy: 1.000 [after 71 batches]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val loss: 1.443 accuracy: 0.582 [after 24 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.038 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.038 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.020 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.253 accuracy: 0.833 [after 71 batches]\n",
            "val loss: 1.647 accuracy: 0.601 [after 24 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.023 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.005 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.029 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 1.987 accuracy: 0.615 [after 24 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.190 accuracy: 0.595 [after 24 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.502 accuracy: 0.593 [after 24 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.598 accuracy: 0.599 [after 24 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.715 accuracy: 0.608 [after 24 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.794 accuracy: 0.612 [after 24 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.850 accuracy: 0.611 [after 24 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.927 accuracy: 0.612 [after 24 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.959 accuracy: 0.615 [after 24 batches]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▆▆████▃████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▅▄▂▂▂▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅█▄▃▅▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▄█▅▅▅▆▅▆▅▆</td></tr><tr><td>val_loss</td><td>▁▂▄▄▆▆▇▇▇██</td></tr><tr><td>val_precision</td><td>▁▅▅▁▁▄▆▄▇▃█</td></tr><tr><td>val_recall</td><td>▁▃█▆▆▅▆▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>11</td></tr><tr><td>step</td><td>43</td></tr><tr><td>train_accuracy</td><td>1.0</td></tr><tr><td>train_loss</td><td>1e-05</td></tr><tr><td>val_accuracy</td><td>0.61458</td></tr><tr><td>val_f1</td><td>0.60886</td></tr><tr><td>val_loss</td><td>2.9586</td></tr><tr><td>val_precision</td><td>0.58986</td></tr><tr><td>val_recall</td><td>0.6652</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lively-sweep-5--1</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/gaxdeh84' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/gaxdeh84</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_105951-gaxdeh84/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_110330-w5xeyr89</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/w5xeyr89' target=\"_blank\">lively-sweep-5--2</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/w5xeyr89' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/w5xeyr89</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=307200, out_features=1, bias=True)\n",
            ")\n",
            "FOLD 3\n",
            "--------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.534 accuracy: 0.750 [after 17 batches]\n",
            "train loss: 0.649 accuracy: 0.750 [after 35 batches]\n",
            "train loss: 0.443 accuracy: 0.812 [after 53 batches]\n",
            "train loss: 0.196 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 1.311 accuracy: 0.583 [after 24 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.029 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.083 accuracy: 0.938 [after 35 batches]\n",
            "train loss: 0.005 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.009 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 1.669 accuracy: 0.591 [after 24 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.004 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.004 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.024 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.156 accuracy: 0.590 [after 24 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.001 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.004 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.309 accuracy: 0.613 [after 24 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.458 accuracy: 0.599 [after 24 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.590 accuracy: 0.590 [after 24 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.657 accuracy: 0.594 [after 24 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.001 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.738 accuracy: 0.597 [after 24 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.790 accuracy: 0.599 [after 24 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.845 accuracy: 0.607 [after 24 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.977 accuracy: 0.615 [after 24 batches]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▁▃██▆██████████████████████████████████</td></tr><tr><td>train_loss</td><td>▇█▆▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃█▅▃▃▄▅▆█</td></tr><tr><td>val_f1</td><td>▁▁▄█▅▃▄▃▄▅▅</td></tr><tr><td>val_loss</td><td>▁▃▅▅▆▆▇▇▇▇█</td></tr><tr><td>val_precision</td><td>▁▅▄██▄▅▅▅▆█</td></tr><tr><td>val_recall</td><td>▃▁▃█▄▃▃▃▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>11</td></tr><tr><td>step</td><td>43</td></tr><tr><td>train_accuracy</td><td>1.0</td></tr><tr><td>train_loss</td><td>6e-05</td></tr><tr><td>val_accuracy</td><td>0.61458</td></tr><tr><td>val_f1</td><td>0.54026</td></tr><tr><td>val_loss</td><td>2.97749</td></tr><tr><td>val_precision</td><td>0.62121</td></tr><tr><td>val_recall</td><td>0.51577</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lively-sweep-5--2</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/w5xeyr89' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/w5xeyr89</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_110330-w5xeyr89/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_110708-lh26imzl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/lh26imzl' target=\"_blank\">lively-sweep-5--3</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/lh26imzl' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/lh26imzl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=307200, out_features=1, bias=True)\n",
            ")\n",
            "FOLD 4\n",
            "--------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.383 accuracy: 0.875 [after 17 batches]\n",
            "train loss: 0.319 accuracy: 0.812 [after 35 batches]\n",
            "train loss: 0.077 accuracy: 0.938 [after 53 batches]\n",
            "train loss: 0.032 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 1.364 accuracy: 0.638 [after 24 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.002 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.017 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.007 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.002 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 1.750 accuracy: 0.700 [after 24 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.003 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.003 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.002 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.108 accuracy: 0.704 [after 24 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.003 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.067 accuracy: 0.687 [after 24 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.001 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.002 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.369 accuracy: 0.693 [after 24 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.468 accuracy: 0.692 [after 24 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.599 accuracy: 0.690 [after 24 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.696 accuracy: 0.689 [after 24 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.775 accuracy: 0.684 [after 24 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.882 accuracy: 0.681 [after 24 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.000 accuracy: 1.000 [after 17 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 35 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 53 batches]\n",
            "train loss: 0.000 accuracy: 1.000 [after 71 batches]\n",
            "val loss: 2.948 accuracy: 0.684 [after 24 batches]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▃▁▆█████████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▇▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁██▆▇▇▇▆▆▆▆</td></tr><tr><td>val_f1</td><td>▁▅█▆▅▅▅▇▆▅▅</td></tr><tr><td>val_loss</td><td>▁▃▄▄▅▆▆▇▇██</td></tr><tr><td>val_precision</td><td>▁█▇█▇▆▇█▇▇▇</td></tr><tr><td>val_recall</td><td>█▁█▇▄▅▃█▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>11</td></tr><tr><td>step</td><td>43</td></tr><tr><td>train_accuracy</td><td>1.0</td></tr><tr><td>train_loss</td><td>0.0</td></tr><tr><td>val_accuracy</td><td>0.68403</td></tr><tr><td>val_f1</td><td>0.55607</td></tr><tr><td>val_loss</td><td>2.94754</td></tr><tr><td>val_precision</td><td>0.7836</td></tr><tr><td>val_recall</td><td>0.45974</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lively-sweep-5--3</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/lh26imzl' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/lh26imzl</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_110708-lh26imzl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_111045-tynhn87r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/tynhn87r' target=\"_blank\">lively-sweep-5</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92' target=\"_blank\">https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92' target=\"_blank\">https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/tynhn87r' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/tynhn87r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_f1</td><td>▁</td></tr><tr><td>val_precision</td><td>▁</td></tr><tr><td>val_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_accuracy</td><td>0.60667</td></tr><tr><td>val_f1</td><td>0.64492</td></tr><tr><td>val_precision</td><td>0.52872</td></tr><tr><td>val_recall</td><td>0.55505</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lively-sweep-5</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/tynhn87r' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/tynhn87r</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 3 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_111045-tynhn87r/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************************************\n",
            "Sweep URL:        https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92\n",
            "Sweep Group URL:  https://wandb.ai/aiuis/dip-project/groups/yad1fy92\n",
            "****************************************\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 95ocfnlx with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tarchitecture: CNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclasses: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdataset: ParkinsonVideo\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfeatures: [16, 32]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_111056-95ocfnlx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/95ocfnlx' target=\"_blank\">dashing-sweep-6</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92' target=\"_blank\">https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92' target=\"_blank\">https://wandb.ai/aiuis/dip-project/sweeps/yad1fy92</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/95ocfnlx' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/95ocfnlx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dashing-sweep-6</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/95ocfnlx' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/95ocfnlx</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_111056-95ocfnlx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>../models/wandb/run-20240601_111106-hyaomiaj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/aiuis/dip-project/runs/hyaomiaj' target=\"_blank\">dashing-sweep-6--0</a></strong> to <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/aiuis/dip-project/runs/hyaomiaj' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/hyaomiaj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=614400, out_features=1, bias=True)\n",
            ")\n",
            "FOLD 1\n",
            "--------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipykernel_4448/1545842686.py\", line 39, in model_pipeline\n",
            "    step = train(model, train_loader, criterion, optimizer, accuracy_fn, step=step)\n",
            "  File \"/tmp/ipykernel_4448/1618031750.py\", line 9, in train\n",
            "    loss, accuracy = train_batch(images, labels, model, optimizer, criterion, metric_fn)\n",
            "  File \"/tmp/ipykernel_4448/2864932988.py\", line 19, in train_batch\n",
            "    outputs = model(images)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1582, in _call_impl\n",
            "    result = forward_call(*args, **kwargs)\n",
            "  File \"/tmp/ipykernel_4448/1407552522.py\", line 38, in forward\n",
            "    out = self.layer1(x)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
            "    input = module(input)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.17 GiB. GPU \n"
          ]
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dashing-sweep-6--0</strong> at: <a href='https://wandb.ai/aiuis/dip-project/runs/hyaomiaj' target=\"_blank\">https://wandb.ai/aiuis/dip-project/runs/hyaomiaj</a><br/> View project at: <a href='https://wandb.ai/aiuis/dip-project' target=\"_blank\">https://wandb.ai/aiuis/dip-project</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>../models/wandb/run-20240601_111106-hyaomiaj/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Run 95ocfnlx errored:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
            "    self._function()\n",
            "  File \"/tmp/ipykernel_4448/2188155363.py\", line 35, in cross_validate\n",
            "    val_accuracy, val_f1, val_recall, val_precision = model_pipeline(\n",
            "  File \"/tmp/ipykernel_4448/1545842686.py\", line 39, in model_pipeline\n",
            "    step = train(model, train_loader, criterion, optimizer, accuracy_fn, step=step)\n",
            "  File \"/tmp/ipykernel_4448/1618031750.py\", line 9, in train\n",
            "    loss, accuracy = train_batch(images, labels, model, optimizer, criterion, metric_fn)\n",
            "  File \"/tmp/ipykernel_4448/2864932988.py\", line 19, in train_batch\n",
            "    outputs = model(images)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1582, in _call_impl\n",
            "    result = forward_call(*args, **kwargs)\n",
            "  File \"/tmp/ipykernel_4448/1407552522.py\", line 38, in forward\n",
            "    out = self.layer1(x)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
            "    input = module(input)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.17 GiB. GPU \n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 95ocfnlx errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/wandb/agents/pyagent.py\", line 307, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_4448/2188155363.py\", line 35, in cross_validate\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     val_accuracy, val_f1, val_recall, val_precision = model_pipeline(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_4448/1545842686.py\", line 39, in model_pipeline\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     step = train(model, train_loader, criterion, optimizer, accuracy_fn, step=step)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_4448/1618031750.py\", line 9, in train\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss, accuracy = train_batch(images, labels, model, optimizer, criterion, metric_fn)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_4448/2864932988.py\", line 19, in train_batch\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     outputs = model(images)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1582, in _call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     result = forward_call(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_4448/1407552522.py\", line 38, in forward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     out = self.layer1(x)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     input = module(input)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._conv_forward(input, self.weight, self.bias)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/home/guillermo/miniforge3/envs/wandb-tutorial/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.conv2d(input, weight, bias, self.stride,\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.17 GiB. GPU \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n"
          ]
        }
      ],
      "source": [
        "# sweep_id = wandb.sweep(sweep_configuration, project='dip-project')\n",
        "wandb.agent(\"yad1fy92\", function=cross_validate, count=3)\n",
        "\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
