{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dftDiCQg3vYy"
      },
      "source": [
        "# <font color='#4C5FDA'>**Breast Cancer Detection Based on CNNs Using Thermal Imaging** </font>\n",
        "\n",
        "Original paper by Juan Pablo Zuluaga, Zeina Al Masry, Khaled Benaggoune, Safa Meraghni & Noureddine Zerhouni: [A CNN-based methodology for breast cancer diagnosis using thermal images](https://www.tandfonline.com/doi/full/10.1080/21681163.2020.1824685)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uraq36CkXB1T",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Instalar paquetes necesarios**\n",
        "\n",
        "%%capture\n",
        "! pip install torchmetrics\n",
        "! pip install wandb -Uq\n",
        "# ! pip install onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#ECA702'>**Clonamos nuestro repo**</font>\n",
        "\n",
        "Esto con el fin de traer todos los .py para poder entrenar 'localmente' en Colab y registrar las métricas en wandb."
      ],
      "metadata": {
        "id": "3eUcjX2Lv5g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gpintoruiz/Thermal-Imaging-Breast-Cancer-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miS2W9Tdwbxq",
        "outputId": "3f457eb2-12bf-47de-bbe0-e2d3df705167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Thermal-Imaging-Breast-Cancer-Detection'...\n",
            "remote: Enumerating objects: 418, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 418 (delta 125), reused 86 (delta 44), pack-reused 220\u001b[K\n",
            "Receiving objects: 100% (418/418), 7.79 MiB | 13.03 MiB/s, done.\n",
            "Resolving deltas: 100% (252/252), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Thermal-Imaging-Breast-Cancer-Detection/notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMuOAySxx1Z1",
        "outputId": "08da5eb4-6a95-41ff-cf8c-0af43daa4db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssFb9A5GyA_u",
        "outputId": "c89bc570-e3c7-49f6-9012-9eb978bc8841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01-gpr-data-exploration-cv2.ipynb   make_dataset.py  train_one_run.py       xception-one-run.yaml\n",
            "0.01-gpr-data-exploration-pil.ipynb   preprocess.py    train.py               xception.py\n",
            "0.04-gpr-colab-experiments.ipynb      resnet56.py      utils.py\n",
            "1.00-gpr-xception-from-scratch.ipynb  test.py          vgg.py\n",
            "alexnet.py                            train_gkfold.py  xception-gfkfold.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkrHeEps3vY3"
      },
      "source": [
        "## <font color='#ECA702'>**Configuración inicial para conectarnos con Kaggle**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJFg6k1x3vY5"
      },
      "source": [
        "1. Instalamos kaggle. Para poder usar comandos de Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwqionQb3vY6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP3nl2Et3vY7"
      },
      "source": [
        "Subimos nuestro token de autenticación de Kaggle (si estamos en colab, sino colocarlo en la carpeta del proyecto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARP6wZsb3vY8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0VPkGso3vY9"
      },
      "source": [
        "1. Creamos los directorios de Kaggle\n",
        "2. Copiamos nuestro token en .kaggle\n",
        "3. Con `chmod 600` establecemos los permitos del token en 600, es decir, que solo yo tengo permisos de lectura y escritura sobre el archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed2nCVTu3vY-"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhQ_SI9x3vZA"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGkGIazz3vZB"
      },
      "source": [
        "## <font color='#ECA702'>**Carga del dataset**</font>\n",
        "\n",
        "Traemos el dataset [Thermal Images for Breast Cancer Diagnosis DMR-IR](https://www.kaggle.com/datasets/asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir) desde kaggle.\n",
        "\n",
        "This dataset is a methodology for breast disease computer-aided diagnosis using dynamic thermography. The thermal images for breast tumors are classified according to DMR-IR standards.\n",
        "\n",
        "Two types of tumors are classified in this dataset one is benign another is malignant.\n",
        "- Benign: This type of tumor is usually well-defined and round or oval in shape. (non-cancerous tumor)\n",
        "- Malignant: This type of tumor is usually poorly defined and irregular with lobules. (cancerous tumor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lmT0aOvG3vZD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! kaggle datasets download -d asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir\n",
        "! unzip thermal-images-for-breast-cancer-diagnosis-dmrir.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QToIa8zB3vZE"
      },
      "source": [
        "Después de descargar los datos. Debemos entender la estructura de las carpetas para poder trabajar con ellas de una mejor manera.\n",
        "1. La carpeta principal `Imagens e Matrizes da Tese de Thiago Alves Elias da Silva` son todos los datos `data`.\n",
        "2. La carpeta `12 Novos Casos de Testes` la podemos tomar como nuestro conjunto de prueba (`test`).\n",
        "3. Mientras que la carpeta `Desenvolvimento da Metodologia` será nuestro conjunto de entrenamiento (`train`).\n",
        "\n",
        "Luego dentro de nuestras carpetas de `train` y `test` encontramos dos categorías `DOENTES`y `SAUDAтХа├╝VEIS` o SAUDÁVEI. Los primeros son los casos malignos y los segundos benignos.\n",
        "\n",
        "Dentro de cada una de las carpetas de pacientes saludables y enfermos se encuentran carpetas con números, cada número representa un paciente. Y para cada paciente tendremos dos carpetas más, una para las imágenes **segmentadas** en escala de grises y la otra para la matrix o mapa de calor.\n",
        "\n",
        "Algo bueno de este dataset es que ya está dividido por pacientes, es decir, no tendremos imagenes del mismo paciente en el conjunto de entrenamiento y testeo. Por lo tanto, vamos a entrenar con N pacientes, y testear con K pacientes, que no son los mismos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#52F17F'>**Partición de los datos**</font>"
      ],
      "metadata": {
        "id": "gvB-mHCPqELO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este comando nos permite cargar funciones de un .py en el entorno local de Colab. [Fuente](https://stackoverflow.com/questions/47345004/in-googles-colab-notebook-how-do-i-call-a-function-from-a-python-file)"
      ],
      "metadata": {
        "id": "753-jlzfrNz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "execfile('make_dataset.py')"
      ],
      "metadata": {
        "id": "0jIUw7ntqHQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2024)\n",
        "\n",
        "def print_fold_patients(folds: dict, data: pd.DataFrame):\n",
        "    for fold_name, indices in folds.items():\n",
        "        train_patients = data.iloc[indices['train']]['patient'].unique()\n",
        "        # val_patients = data.iloc[indices['val']]['patient'].unique()\n",
        "        test_patients = data.iloc[indices['test']]['patient'].unique()\n",
        "\n",
        "        print(f\"{fold_name}:\\n\")\n",
        "        print(f\"Train patients: {train_patients}\")\n",
        "        # print(f\"Validation patients: {val_patients}\")\n",
        "        print(f\"Test patients: {test_patients}\\n\")\n",
        "\n",
        "# Generar los datos\n",
        "data = make_dataframe()\n",
        "\n",
        "# Generar los folds\n",
        "folds = make_folds(data)\n",
        "\n",
        "# Imprimir los pacientes por cada fold\n",
        "print_fold_patients(folds, data)"
      ],
      "metadata": {
        "id": "wI2woWQCqxcO",
        "outputId": "2306b952-0556-41b8-b3f8-dcd034c462da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold_1:\n",
            "\n",
            "Train patients: ['48' '14' '69' '63' '66' '65' '62' '46' '15' '45' '43' '13' '38' '44'\n",
            " '39' '41' '42' '16' '40' '37' '17' '36' '05' '53' '31' '03' '06' '55'\n",
            " '56' '24' '01' '51' '09' '04' '00' '25' '58' '52' '02' '49' '29' '35'\n",
            " '27' '32' '08' '59' '30' '28']\n",
            "Test patients: ['61' '64' '34' '11' '26' '07' '60' '54']\n",
            "\n",
            "fold_2:\n",
            "\n",
            "Train patients: ['48' '14' '63' '61' '66' '64' '65' '15' '45' '43' '13' '38' '44' '39'\n",
            " '41' '42' '16' '34' '11' '40' '37' '17' '36' '03' '06' '55' '56' '24'\n",
            " '26' '01' '51' '09' '04' '00' '25' '58' '52' '07' '60' '49' '29' '35'\n",
            " '32' '08' '59' '54' '30' '28']\n",
            "Test patients: ['69' '62' '46' '05' '53' '31' '02' '27']\n",
            "\n",
            "fold_3:\n",
            "\n",
            "Train patients: ['48' '69' '61' '66' '64' '65' '62' '46' '15' '43' '13' '38' '44' '39'\n",
            " '41' '42' '16' '34' '11' '40' '37' '05' '53' '31' '03' '55' '56' '24'\n",
            " '26' '01' '51' '09' '04' '00' '25' '58' '07' '60' '02' '49' '29' '35'\n",
            " '27' '32' '08' '59' '54' '30']\n",
            "Test patients: ['14' '63' '45' '17' '36' '06' '52' '28']\n",
            "\n",
            "fold_4:\n",
            "\n",
            "Train patients: ['14' '69' '63' '61' '66' '64' '65' '62' '46' '15' '45' '43' '13' '38'\n",
            " '44' '41' '42' '34' '11' '40' '37' '17' '36' '05' '53' '31' '03' '06'\n",
            " '55' '56' '24' '26' '01' '09' '00' '25' '58' '52' '07' '60' '02' '27'\n",
            " '32' '08' '59' '54' '30' '28']\n",
            "Test patients: ['48' '39' '16' '51' '04' '49' '29' '35']\n",
            "\n",
            "fold_5:\n",
            "\n",
            "Train patients: ['48' '14' '69' '63' '61' '66' '64' '65' '62' '46' '45' '43' '13' '44'\n",
            " '39' '41' '16' '34' '11' '40' '37' '17' '36' '05' '53' '31' '06' '55'\n",
            " '56' '24' '26' '01' '51' '09' '04' '00' '25' '52' '07' '60' '02' '49'\n",
            " '29' '35' '27' '08' '54' '28']\n",
            "Test patients: ['15' '38' '42' '03' '58' '32' '59' '30']\n",
            "\n",
            "fold_6:\n",
            "\n",
            "Train patients: ['48' '14' '69' '63' '61' '64' '65' '62' '46' '15' '45' '13' '38' '44'\n",
            " '39' '41' '42' '16' '34' '11' '17' '36' '05' '53' '31' '03' '06' '55'\n",
            " '26' '51' '04' '00' '25' '58' '52' '07' '60' '02' '49' '29' '35' '27'\n",
            " '32' '08' '59' '54' '30' '28']\n",
            "Test patients: ['66' '43' '40' '37' '56' '24' '01' '09']\n",
            "\n",
            "fold_7:\n",
            "\n",
            "Train patients: ['48' '14' '69' '63' '61' '66' '64' '62' '46' '15' '45' '43' '38' '39'\n",
            " '42' '16' '34' '11' '40' '37' '17' '36' '05' '53' '31' '03' '06' '56'\n",
            " '24' '26' '01' '51' '09' '04' '58' '52' '07' '60' '02' '49' '29' '35'\n",
            " '27' '32' '59' '54' '30' '28']\n",
            "Test patients: ['65' '13' '44' '41' '55' '00' '25' '08']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#ECA702'>**Inicializamos el agende de wandb**</font>"
      ],
      "metadata": {
        "id": "5YTKbsdDyqSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#52F17F'>**1. Nos logeamos en nuestra cuenta**</font>"
      ],
      "metadata": {
        "id": "nIskv2fHy4Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "St3agN3Rypzq",
        "outputId": "8173c45a-4d1c-43cd-ece0-d050a6986c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#52F17F'>**2. Hacemos call del agente**</font>\n"
      ],
      "metadata": {
        "id": "w0r-E8Ufy9TQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El sweep que estoy probando acá es el [siguiente](https://github.com/gpintoruiz/Thermal-Imaging-Breast-Cancer-Detection/blob/main/notebooks/xception-one-run.yaml). Se pueden cambiar los parámetros a probar como tú quieras de acuerdo con la [documentación](https://docs.wandb.ai/guides/sweeps/define-sweep-configuration) (recomiendo solo cambiar la arquitectura para que las comparaciones entre modelos sean equivalentes).\n",
        "\n",
        "Si no tienes ni idea qué es un sweep mira el siguiente [tutorial](https://www.youtube.com/watch?v=9zrmUIlScdY&t=1361s&ab_channel=Weights%26Biases).\n",
        "\n",
        "El comando `--count` sirve para decirle al agente cuántos runs hacer, aplica especialmente cuando el método del sweep es `bayes` o `random`\n"
      ],
      "metadata": {
        "id": "LxtyncVoCVL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wandb agent aiuis/dip-project/5oq5gka9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpG6dTZdy0R3",
        "outputId": "fa5100dc-3442-4b0a-8b91-e0833040727a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
            "2024-07-04 18:22:41,524 - wandb.wandb_agent - INFO - Running runs: []\n",
            "2024-07-04 18:22:41,716 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2024-07-04 18:22:41,716 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tarchitecture: xception\n",
            "\taugmented: True\n",
            "\tbatch_size: 64\n",
            "\tcrop: True\n",
            "\tlearning_rate: 0.0006177338121893195\n",
            "\tnormalize: False\n",
            "\toptimizer: adam\n",
            "2024-07-04 18:22:41,718 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train_gkfold.py --architecture=xception --augmented=True --batch_size=64 --crop=True --learning_rate=0.0006177338121893195 --normalize=False --optimizer=adam\n",
            "2024-07-04 18:22:46,730 - wandb.wandb_agent - INFO - Running runs: ['51i3330j']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgpintoruiz\u001b[0m (\u001b[33maiuis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240704_182248-51i3330j\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-sweep-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/sweeps/5oq5gka9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/51i3330j\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilver-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/51i3330j\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240704_182248-51i3330j/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240704_182254-kh3b1x32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-sweep-1--1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/kh3b1x32\u001b[0m\n",
            "FOLD 1\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.771 accuracy: 0.553 [after 4 batches]\n",
            "train loss: 0.591 accuracy: 0.702 [after 9 batches]\n",
            "train loss: 0.473 accuracy: 0.770 [after 14 batches]\n",
            "train loss: 0.417 accuracy: 0.806 [after 19 batches]\n",
            "test loss: 0.724 accuracy: 0.363 recall: 0.000 precision: 0.000 f1: 0.000 [after 4 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.194 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.183 accuracy: 0.942 [after 9 batches]\n",
            "train loss: 0.207 accuracy: 0.934 [after 14 batches]\n",
            "train loss: 0.200 accuracy: 0.938 [after 19 batches]\n",
            "test loss: 0.615 accuracy: 0.807 recall: 0.962 precision: 0.762 f1: 0.849 [after 4 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.259 accuracy: 0.894 [after 4 batches]\n",
            "train loss: 0.256 accuracy: 0.894 [after 9 batches]\n",
            "train loss: 0.226 accuracy: 0.911 [after 14 batches]\n",
            "train loss: 0.221 accuracy: 0.917 [after 19 batches]\n",
            "test loss: 0.364 accuracy: 0.833 recall: 0.809 precision: 0.756 f1: 0.781 [after 4 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.231 accuracy: 0.884 [after 4 batches]\n",
            "train loss: 0.208 accuracy: 0.913 [after 9 batches]\n",
            "train loss: 0.209 accuracy: 0.916 [after 14 batches]\n",
            "train loss: 0.217 accuracy: 0.914 [after 19 batches]\n",
            "test loss: 0.205 accuracy: 0.928 recall: 0.882 precision: 1.000 f1: 0.936 [after 4 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.164 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.212 accuracy: 0.923 [after 9 batches]\n",
            "train loss: 0.223 accuracy: 0.918 [after 14 batches]\n",
            "train loss: 0.221 accuracy: 0.920 [after 19 batches]\n",
            "test loss: 0.502 accuracy: 0.679 recall: 0.925 precision: 0.673 f1: 0.777 [after 4 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.217 accuracy: 0.916 [after 4 batches]\n",
            "train loss: 0.190 accuracy: 0.934 [after 9 batches]\n",
            "train loss: 0.175 accuracy: 0.942 [after 14 batches]\n",
            "train loss: 0.179 accuracy: 0.941 [after 19 batches]\n",
            "test loss: 0.235 accuracy: 0.914 recall: 0.906 precision: 0.951 f1: 0.927 [after 4 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.246 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.244 accuracy: 0.906 [after 9 batches]\n",
            "train loss: 0.235 accuracy: 0.913 [after 14 batches]\n",
            "train loss: 0.257 accuracy: 0.909 [after 19 batches]\n",
            "test loss: 0.279 accuracy: 0.906 recall: 0.844 precision: 1.000 f1: 0.912 [after 4 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.244 accuracy: 0.919 [after 4 batches]\n",
            "train loss: 0.252 accuracy: 0.908 [after 9 batches]\n",
            "train loss: 0.253 accuracy: 0.905 [after 14 batches]\n",
            "train loss: 0.246 accuracy: 0.910 [after 19 batches]\n",
            "test loss: 0.941 accuracy: 0.710 recall: 0.881 precision: 0.708 f1: 0.783 [after 4 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.170 accuracy: 0.947 [after 4 batches]\n",
            "train loss: 0.166 accuracy: 0.945 [after 9 batches]\n",
            "train loss: 0.173 accuracy: 0.945 [after 14 batches]\n",
            "train loss: 0.200 accuracy: 0.931 [after 19 batches]\n",
            "test loss: 0.609 accuracy: 0.768 recall: 0.905 precision: 0.753 f1: 0.820 [after 4 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.287 accuracy: 0.887 [after 4 batches]\n",
            "train loss: 0.249 accuracy: 0.908 [after 9 batches]\n",
            "train loss: 0.237 accuracy: 0.913 [after 14 batches]\n",
            "train loss: 0.229 accuracy: 0.914 [after 19 batches]\n",
            "test loss: 0.330 accuracy: 0.834 recall: 0.863 precision: 0.873 f1: 0.866 [after 4 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.203 accuracy: 0.925 [after 4 batches]\n",
            "train loss: 0.201 accuracy: 0.930 [after 9 batches]\n",
            "train loss: 0.186 accuracy: 0.931 [after 14 batches]\n",
            "train loss: 0.180 accuracy: 0.933 [after 19 batches]\n",
            "test loss: 0.306 accuracy: 0.837 recall: 0.911 precision: 0.834 f1: 0.863 [after 4 batches]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train loss: 0.179 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.197 accuracy: 0.931 [after 9 batches]\n",
            "train loss: 0.189 accuracy: 0.929 [after 14 batches]\n",
            "train loss: 0.197 accuracy: 0.925 [after 19 batches]\n",
            "test loss: 0.282 accuracy: 0.914 recall: 0.863 precision: 0.992 f1: 0.921 [after 4 batches]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "train loss: 0.172 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.184 accuracy: 0.933 [after 9 batches]\n",
            "train loss: 0.165 accuracy: 0.942 [after 14 batches]\n",
            "train loss: 0.171 accuracy: 0.942 [after 19 batches]\n",
            "test loss: 0.352 accuracy: 0.845 recall: 0.788 precision: 0.933 f1: 0.846 [after 4 batches]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "train loss: 0.228 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.195 accuracy: 0.927 [after 9 batches]\n",
            "train loss: 0.200 accuracy: 0.924 [after 14 batches]\n",
            "train loss: 0.193 accuracy: 0.929 [after 19 batches]\n",
            "test loss: 0.319 accuracy: 0.897 recall: 0.835 precision: 1.000 f1: 0.910 [after 4 batches]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▂▃▃▄▄▅▅▆▆▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁▇▇█▅██▅▆▇▇█▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 ▁▇▇█▇██▇▇▇▇█▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision ▁▆▆█▆██▆▆▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall ▁█▇▇██▇▇█▇█▇▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄▅███▇▇▇▇▇▇█▇████▇▇▇▇▇███▇▇▇████████▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▆▅▁▁▁▂▂▂▂▂▂▁▂▂▁▁▁▂▂▂▂▂▁▁▁▂▂▂▁▁▁▁▁▁▁▁▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 14\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step 55\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.89688\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 0.9096\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall 0.83542\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.92891\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.19289\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilver-sweep-1--1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/kh3b1x32\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 6 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240704_182254-kh3b1x32/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240704_184101-86zsr5if\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-sweep-1--2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/86zsr5if\u001b[0m\n",
            "FOLD 2\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.782 accuracy: 0.534 [after 4 batches]\n",
            "train loss: 0.552 accuracy: 0.714 [after 9 batches]\n",
            "train loss: 0.464 accuracy: 0.777 [after 14 batches]\n",
            "train loss: 0.407 accuracy: 0.812 [after 19 batches]\n",
            "test loss: 0.656 accuracy: 0.348 recall: 0.000 precision: 0.000 f1: 0.000 [after 4 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.301 accuracy: 0.891 [after 4 batches]\n",
            "train loss: 0.252 accuracy: 0.903 [after 9 batches]\n",
            "train loss: 0.256 accuracy: 0.904 [after 14 batches]\n",
            "train loss: 0.259 accuracy: 0.902 [after 19 batches]\n",
            "test loss: 0.942 accuracy: 0.808 recall: 0.687 precision: 1.000 f1: 0.814 [after 4 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.254 accuracy: 0.887 [after 4 batches]\n",
            "train loss: 0.204 accuracy: 0.916 [after 9 batches]\n",
            "train loss: 0.204 accuracy: 0.918 [after 14 batches]\n",
            "train loss: 0.197 accuracy: 0.920 [after 19 batches]\n",
            "test loss: 0.459 accuracy: 0.924 recall: 0.882 precision: 1.000 f1: 0.936 [after 4 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.251 accuracy: 0.903 [after 4 batches]\n",
            "train loss: 0.229 accuracy: 0.919 [after 9 batches]\n",
            "train loss: 0.237 accuracy: 0.916 [after 14 batches]\n",
            "train loss: 0.221 accuracy: 0.922 [after 19 batches]\n",
            "test loss: 0.418 accuracy: 0.940 recall: 0.908 precision: 1.000 f1: 0.952 [after 4 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.237 accuracy: 0.887 [after 4 batches]\n",
            "train loss: 0.227 accuracy: 0.900 [after 9 batches]\n",
            "train loss: 0.223 accuracy: 0.903 [after 14 batches]\n",
            "train loss: 0.217 accuracy: 0.908 [after 19 batches]\n",
            "test loss: 0.553 accuracy: 0.914 recall: 0.869 precision: 1.000 f1: 0.929 [after 4 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.195 accuracy: 0.925 [after 4 batches]\n",
            "train loss: 0.182 accuracy: 0.927 [after 9 batches]\n",
            "train loss: 0.183 accuracy: 0.928 [after 14 batches]\n",
            "train loss: 0.181 accuracy: 0.930 [after 19 batches]\n",
            "test loss: 0.901 accuracy: 0.907 recall: 0.853 precision: 1.000 f1: 0.920 [after 4 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.187 accuracy: 0.925 [after 4 batches]\n",
            "train loss: 0.173 accuracy: 0.930 [after 9 batches]\n",
            "train loss: 0.200 accuracy: 0.915 [after 14 batches]\n",
            "train loss: 0.189 accuracy: 0.923 [after 19 batches]\n",
            "test loss: 0.340 accuracy: 0.875 recall: 0.816 precision: 1.000 f1: 0.895 [after 4 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.219 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.185 accuracy: 0.917 [after 9 batches]\n",
            "train loss: 0.188 accuracy: 0.916 [after 14 batches]\n",
            "train loss: 0.181 accuracy: 0.920 [after 19 batches]\n",
            "test loss: 0.319 accuracy: 0.940 recall: 0.905 precision: 1.000 f1: 0.950 [after 4 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.129 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.176 accuracy: 0.928 [after 9 batches]\n",
            "train loss: 0.186 accuracy: 0.924 [after 14 batches]\n",
            "train loss: 0.181 accuracy: 0.925 [after 19 batches]\n",
            "test loss: 0.336 accuracy: 0.957 recall: 0.932 precision: 1.000 f1: 0.964 [after 4 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.176 accuracy: 0.928 [after 4 batches]\n",
            "train loss: 0.152 accuracy: 0.938 [after 9 batches]\n",
            "train loss: 0.152 accuracy: 0.936 [after 14 batches]\n",
            "train loss: 0.150 accuracy: 0.940 [after 19 batches]\n",
            "test loss: 0.379 accuracy: 0.940 recall: 0.907 precision: 1.000 f1: 0.951 [after 4 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.099 accuracy: 0.963 [after 4 batches]\n",
            "train loss: 0.158 accuracy: 0.938 [after 9 batches]\n",
            "train loss: 0.157 accuracy: 0.938 [after 14 batches]\n",
            "train loss: 0.160 accuracy: 0.937 [after 19 batches]\n",
            "test loss: 0.470 accuracy: 0.931 recall: 0.896 precision: 1.000 f1: 0.945 [after 4 batches]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train loss: 0.120 accuracy: 0.959 [after 4 batches]\n",
            "train loss: 0.164 accuracy: 0.944 [after 9 batches]\n",
            "train loss: 0.175 accuracy: 0.934 [after 14 batches]\n",
            "train loss: 0.165 accuracy: 0.940 [after 19 batches]\n",
            "test loss: 0.657 accuracy: 0.876 recall: 0.813 precision: 1.000 f1: 0.895 [after 4 batches]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "train loss: 0.149 accuracy: 0.953 [after 4 batches]\n",
            "train loss: 0.166 accuracy: 0.938 [after 9 batches]\n",
            "train loss: 0.147 accuracy: 0.945 [after 14 batches]\n",
            "train loss: 0.144 accuracy: 0.947 [after 19 batches]\n",
            "test loss: 0.288 accuracy: 0.919 recall: 0.871 precision: 1.000 f1: 0.931 [after 4 batches]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "train loss: 0.172 accuracy: 0.922 [after 4 batches]\n",
            "train loss: 0.161 accuracy: 0.930 [after 9 batches]\n",
            "train loss: 0.150 accuracy: 0.934 [after 14 batches]\n",
            "train loss: 0.154 accuracy: 0.934 [after 19 batches]\n",
            "test loss: 0.621 accuracy: 0.921 recall: 0.874 precision: 1.000 f1: 0.931 [after 4 batches]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "train loss: 0.177 accuracy: 0.909 [after 4 batches]\n",
            "train loss: 0.183 accuracy: 0.916 [after 9 batches]\n",
            "train loss: 0.170 accuracy: 0.922 [after 14 batches]\n",
            "train loss: 0.165 accuracy: 0.929 [after 19 batches]\n",
            "test loss: 0.310 accuracy: 0.924 recall: 0.882 precision: 1.000 f1: 0.937 [after 4 batches]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "train loss: 0.160 accuracy: 0.928 [after 4 batches]\n",
            "train loss: 0.134 accuracy: 0.948 [after 9 batches]\n",
            "train loss: 0.147 accuracy: 0.939 [after 14 batches]\n",
            "train loss: 0.151 accuracy: 0.937 [after 19 batches]\n",
            "test loss: 0.459 accuracy: 0.929 recall: 0.887 precision: 1.000 f1: 0.939 [after 4 batches]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "train loss: 0.175 accuracy: 0.925 [after 4 batches]\n",
            "train loss: 0.157 accuracy: 0.934 [after 9 batches]\n",
            "train loss: 0.139 accuracy: 0.943 [after 14 batches]\n",
            "train loss: 0.127 accuracy: 0.948 [after 19 batches]\n",
            "test loss: 0.263 accuracy: 0.924 recall: 0.879 precision: 1.000 f1: 0.934 [after 4 batches]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "train loss: 0.138 accuracy: 0.956 [after 4 batches]\n",
            "train loss: 0.144 accuracy: 0.953 [after 9 batches]\n",
            "train loss: 0.145 accuracy: 0.952 [after 14 batches]\n",
            "train loss: 0.135 accuracy: 0.953 [after 19 batches]\n",
            "test loss: 0.319 accuracy: 0.931 recall: 0.896 precision: 1.000 f1: 0.945 [after 4 batches]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "train loss: 0.114 accuracy: 0.956 [after 4 batches]\n",
            "train loss: 0.164 accuracy: 0.942 [after 9 batches]\n",
            "train loss: 0.169 accuracy: 0.936 [after 14 batches]\n",
            "train loss: 0.165 accuracy: 0.940 [after 19 batches]\n",
            "test loss: 0.701 accuracy: 0.898 recall: 0.840 precision: 1.000 f1: 0.910 [after 4 batches]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "train loss: 0.170 accuracy: 0.931 [after 4 batches]\n",
            "train loss: 0.148 accuracy: 0.941 [after 9 batches]\n",
            "train loss: 0.138 accuracy: 0.943 [after 14 batches]\n",
            "train loss: 0.143 accuracy: 0.944 [after 19 batches]\n",
            "test loss: 1.262 accuracy: 0.920 recall: 0.872 precision: 1.000 f1: 0.932 [after 4 batches]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "train loss: 0.140 accuracy: 0.947 [after 4 batches]\n",
            "train loss: 0.130 accuracy: 0.955 [after 9 batches]\n",
            "train loss: 0.123 accuracy: 0.954 [after 14 batches]\n",
            "train loss: 0.130 accuracy: 0.949 [after 19 batches]\n",
            "test loss: 0.532 accuracy: 0.847 recall: 0.907 precision: 0.866 f1: 0.884 [after 4 batches]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "train loss: 0.142 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.143 accuracy: 0.953 [after 9 batches]\n",
            "train loss: 0.147 accuracy: 0.952 [after 14 batches]\n",
            "train loss: 0.140 accuracy: 0.951 [after 19 batches]\n",
            "test loss: 0.218 accuracy: 0.960 recall: 0.939 precision: 1.000 f1: 0.968 [after 4 batches]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "train loss: 0.169 accuracy: 0.928 [after 4 batches]\n",
            "train loss: 0.156 accuracy: 0.938 [after 9 batches]\n",
            "train loss: 0.141 accuracy: 0.945 [after 14 batches]\n",
            "train loss: 0.170 accuracy: 0.934 [after 19 batches]\n",
            "test loss: 0.906 accuracy: 0.864 recall: 0.786 precision: 1.000 f1: 0.878 [after 4 batches]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "train loss: 0.153 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.192 accuracy: 0.925 [after 9 batches]\n",
            "train loss: 0.184 accuracy: 0.933 [after 14 batches]\n",
            "train loss: 0.172 accuracy: 0.938 [after 19 batches]\n",
            "test loss: 0.328 accuracy: 0.936 recall: 0.902 precision: 1.000 f1: 0.948 [after 4 batches]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "train loss: 0.161 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.156 accuracy: 0.934 [after 9 batches]\n",
            "train loss: 0.140 accuracy: 0.945 [after 14 batches]\n",
            "train loss: 0.139 accuracy: 0.945 [after 19 batches]\n",
            "test loss: 0.468 accuracy: 0.896 recall: 0.837 precision: 1.000 f1: 0.911 [after 4 batches]\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "train loss: 0.144 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.141 accuracy: 0.942 [after 9 batches]\n",
            "train loss: 0.141 accuracy: 0.940 [after 14 batches]\n",
            "train loss: 0.134 accuracy: 0.945 [after 19 batches]\n",
            "test loss: 0.583 accuracy: 0.931 recall: 0.894 precision: 1.000 f1: 0.944 [after 4 batches]\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "train loss: 0.072 accuracy: 0.969 [after 4 batches]\n",
            "train loss: 0.085 accuracy: 0.959 [after 9 batches]\n",
            "train loss: 0.108 accuracy: 0.951 [after 14 batches]\n",
            "train loss: 0.100 accuracy: 0.957 [after 19 batches]\n",
            "test loss: 0.302 accuracy: 0.944 recall: 0.911 precision: 1.000 f1: 0.953 [after 4 batches]\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "train loss: 0.115 accuracy: 0.963 [after 4 batches]\n",
            "train loss: 0.125 accuracy: 0.950 [after 9 batches]\n",
            "train loss: 0.138 accuracy: 0.943 [after 14 batches]\n",
            "train loss: 0.130 accuracy: 0.947 [after 19 batches]\n",
            "test loss: 0.738 accuracy: 0.887 recall: 0.841 precision: 1.000 f1: 0.911 [after 4 batches]\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "train loss: 0.101 accuracy: 0.972 [after 4 batches]\n",
            "train loss: 0.125 accuracy: 0.956 [after 9 batches]\n",
            "train loss: 0.112 accuracy: 0.959 [after 14 batches]\n",
            "train loss: 0.108 accuracy: 0.963 [after 19 batches]\n",
            "test loss: 0.653 accuracy: 0.924 recall: 0.880 precision: 1.000 f1: 0.936 [after 4 batches]\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "train loss: 0.085 accuracy: 0.966 [after 4 batches]\n",
            "train loss: 0.098 accuracy: 0.961 [after 9 batches]\n",
            "train loss: 0.113 accuracy: 0.958 [after 14 batches]\n",
            "train loss: 0.134 accuracy: 0.946 [after 19 batches]\n",
            "test loss: 0.279 accuracy: 0.915 recall: 0.908 precision: 0.961 f1: 0.933 [after 4 batches]\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "train loss: 0.110 accuracy: 0.953 [after 4 batches]\n",
            "train loss: 0.122 accuracy: 0.956 [after 9 batches]\n",
            "train loss: 0.105 accuracy: 0.963 [after 14 batches]\n",
            "train loss: 0.102 accuracy: 0.963 [after 19 batches]\n",
            "test loss: 0.540 accuracy: 0.924 recall: 0.881 precision: 1.000 f1: 0.937 [after 4 batches]\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "train loss: 0.064 accuracy: 0.981 [after 4 batches]\n",
            "train loss: 0.057 accuracy: 0.984 [after 9 batches]\n",
            "train loss: 0.053 accuracy: 0.985 [after 14 batches]\n",
            "train loss: 0.071 accuracy: 0.982 [after 19 batches]\n",
            "test loss: 0.735 accuracy: 0.912 recall: 0.864 precision: 1.000 f1: 0.927 [after 4 batches]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁▆██▇▇▇████▇██████▇█▇█▇█▇██▇█▇█▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 ▁▇████▇████▇████████▇█▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision ▁███████████████████▇███████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall ▁▆██▇▇▇████▇▇█████▇███▇█▇██▇███▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▆▄▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▁▂▂▁▂▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step 127\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.91183\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 0.92665\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall 0.86396\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.98203\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.07131\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilver-sweep-1--2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/86zsr5if\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 10 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240704_184101-86zsr5if/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240704_192039-ykbamlid\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-sweep-1--3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/ykbamlid\u001b[0m\n",
            "FOLD 3\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.821 accuracy: 0.519 [after 4 batches]\n",
            "train loss: 0.707 accuracy: 0.603 [after 9 batches]\n",
            "train loss: 0.566 accuracy: 0.705 [after 14 batches]\n",
            "train loss: 0.514 accuracy: 0.743 [after 19 batches]\n",
            "test loss: 0.982 accuracy: 0.539 recall: 0.000 precision: 0.000 f1: 0.000 [after 4 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.232 accuracy: 0.922 [after 4 batches]\n",
            "train loss: 0.265 accuracy: 0.906 [after 9 batches]\n",
            "train loss: 0.250 accuracy: 0.914 [after 14 batches]\n",
            "train loss: 0.241 accuracy: 0.915 [after 19 batches]\n",
            "test loss: 1.768 accuracy: 0.613 recall: 1.000 precision: 0.534 f1: 0.694 [after 4 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.175 accuracy: 0.941 [after 4 batches]\n",
            "train loss: 0.170 accuracy: 0.942 [after 9 batches]\n",
            "train loss: 0.223 accuracy: 0.920 [after 14 batches]\n",
            "train loss: 0.240 accuracy: 0.909 [after 19 batches]\n",
            "test loss: 1.070 accuracy: 0.570 recall: 1.000 precision: 0.509 f1: 0.674 [after 4 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.209 accuracy: 0.928 [after 4 batches]\n",
            "train loss: 0.231 accuracy: 0.916 [after 9 batches]\n",
            "train loss: 0.223 accuracy: 0.919 [after 14 batches]\n",
            "train loss: 0.223 accuracy: 0.918 [after 19 batches]\n",
            "test loss: 0.864 accuracy: 0.647 recall: 0.990 precision: 0.568 f1: 0.717 [after 4 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.281 accuracy: 0.884 [after 4 batches]\n",
            "train loss: 0.263 accuracy: 0.898 [after 9 batches]\n",
            "train loss: 0.254 accuracy: 0.900 [after 14 batches]\n",
            "train loss: 0.247 accuracy: 0.905 [after 19 batches]\n",
            "test loss: 0.103 accuracy: 0.980 recall: 0.958 precision: 1.000 f1: 0.978 [after 4 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.247 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.247 accuracy: 0.908 [after 9 batches]\n",
            "train loss: 0.255 accuracy: 0.903 [after 14 batches]\n",
            "train loss: 0.265 accuracy: 0.895 [after 19 batches]\n",
            "test loss: 0.277 accuracy: 0.846 recall: 0.969 precision: 0.753 f1: 0.847 [after 4 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.203 accuracy: 0.925 [after 4 batches]\n",
            "train loss: 0.188 accuracy: 0.930 [after 9 batches]\n",
            "train loss: 0.201 accuracy: 0.922 [after 14 batches]\n",
            "train loss: 0.221 accuracy: 0.919 [after 19 batches]\n",
            "test loss: 0.113 accuracy: 0.983 recall: 0.958 precision: 1.000 f1: 0.978 [after 4 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.171 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.195 accuracy: 0.938 [after 9 batches]\n",
            "train loss: 0.215 accuracy: 0.922 [after 14 batches]\n",
            "train loss: 0.224 accuracy: 0.915 [after 19 batches]\n",
            "test loss: 0.172 accuracy: 0.948 recall: 0.957 precision: 0.931 f1: 0.942 [after 4 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.252 accuracy: 0.913 [after 4 batches]\n",
            "train loss: 0.228 accuracy: 0.913 [after 9 batches]\n",
            "train loss: 0.227 accuracy: 0.919 [after 14 batches]\n",
            "train loss: 0.211 accuracy: 0.925 [after 19 batches]\n",
            "test loss: 0.136 accuracy: 0.961 recall: 0.935 precision: 0.991 f1: 0.961 [after 4 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.162 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.175 accuracy: 0.928 [after 9 batches]\n",
            "train loss: 0.204 accuracy: 0.926 [after 14 batches]\n",
            "train loss: 0.187 accuracy: 0.931 [after 19 batches]\n",
            "test loss: 0.069 accuracy: 0.988 recall: 0.973 precision: 1.000 f1: 0.986 [after 4 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.152 accuracy: 0.947 [after 4 batches]\n",
            "train loss: 0.194 accuracy: 0.936 [after 9 batches]\n",
            "train loss: 0.209 accuracy: 0.927 [after 14 batches]\n",
            "train loss: 0.206 accuracy: 0.925 [after 19 batches]\n",
            "test loss: 0.142 accuracy: 0.984 recall: 0.974 precision: 0.991 f1: 0.982 [after 4 batches]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train loss: 0.170 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.159 accuracy: 0.944 [after 9 batches]\n",
            "train loss: 0.189 accuracy: 0.927 [after 14 batches]\n",
            "train loss: 0.214 accuracy: 0.916 [after 19 batches]\n",
            "test loss: 0.152 accuracy: 0.992 recall: 0.983 precision: 1.000 f1: 0.991 [after 4 batches]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "train loss: 0.253 accuracy: 0.897 [after 4 batches]\n",
            "train loss: 0.226 accuracy: 0.906 [after 9 batches]\n",
            "train loss: 0.217 accuracy: 0.913 [after 14 batches]\n",
            "train loss: 0.197 accuracy: 0.923 [after 19 batches]\n",
            "test loss: 0.753 accuracy: 0.696 recall: 0.970 precision: 0.599 f1: 0.740 [after 4 batches]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "train loss: 0.156 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.182 accuracy: 0.939 [after 9 batches]\n",
            "train loss: 0.179 accuracy: 0.940 [after 14 batches]\n",
            "train loss: 0.200 accuracy: 0.927 [after 19 batches]\n",
            "test loss: 0.098 accuracy: 0.972 recall: 0.937 precision: 1.000 f1: 0.966 [after 4 batches]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "train loss: 0.216 accuracy: 0.934 [after 4 batches]\n",
            "train loss: 0.223 accuracy: 0.920 [after 9 batches]\n",
            "train loss: 0.211 accuracy: 0.928 [after 14 batches]\n",
            "train loss: 0.210 accuracy: 0.930 [after 19 batches]\n",
            "test loss: 0.511 accuracy: 0.746 recall: 0.970 precision: 0.641 f1: 0.770 [after 4 batches]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "train loss: 0.199 accuracy: 0.919 [after 4 batches]\n",
            "train loss: 0.231 accuracy: 0.905 [after 9 batches]\n",
            "train loss: 0.216 accuracy: 0.917 [after 14 batches]\n",
            "train loss: 0.200 accuracy: 0.924 [after 19 batches]\n",
            "test loss: 0.091 accuracy: 0.984 recall: 0.975 precision: 0.992 f1: 0.983 [after 4 batches]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "train loss: 0.221 accuracy: 0.922 [after 4 batches]\n",
            "train loss: 0.215 accuracy: 0.925 [after 9 batches]\n",
            "train loss: 0.205 accuracy: 0.931 [after 14 batches]\n",
            "train loss: 0.185 accuracy: 0.936 [after 19 batches]\n",
            "test loss: 0.320 accuracy: 0.891 recall: 0.948 precision: 0.825 f1: 0.882 [after 4 batches]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "train loss: 0.209 accuracy: 0.919 [after 4 batches]\n",
            "train loss: 0.200 accuracy: 0.923 [after 9 batches]\n",
            "train loss: 0.181 accuracy: 0.936 [after 14 batches]\n",
            "train loss: 0.193 accuracy: 0.934 [after 19 batches]\n",
            "test loss: 0.324 accuracy: 0.912 recall: 0.974 precision: 0.855 f1: 0.910 [after 4 batches]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "train loss: 0.209 accuracy: 0.916 [after 4 batches]\n",
            "train loss: 0.193 accuracy: 0.925 [after 9 batches]\n",
            "train loss: 0.211 accuracy: 0.921 [after 14 batches]\n",
            "train loss: 0.198 accuracy: 0.927 [after 19 batches]\n",
            "test loss: 0.096 accuracy: 0.969 recall: 0.933 precision: 1.000 f1: 0.965 [after 4 batches]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "train loss: 0.201 accuracy: 0.916 [after 4 batches]\n",
            "train loss: 0.207 accuracy: 0.917 [after 9 batches]\n",
            "train loss: 0.197 accuracy: 0.921 [after 14 batches]\n",
            "train loss: 0.186 accuracy: 0.928 [after 19 batches]\n",
            "test loss: 0.146 accuracy: 0.988 recall: 0.975 precision: 1.000 f1: 0.987 [after 4 batches]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁▂▁▃█▆█▇████▃█▄█▆▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 ▁▆▆▆█▇██████▆█▆█▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision ▁▅▅▅█▆██████▅█▅█▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall ▁███████████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄█▇███▇▇▇▇▇████▇▇██████▇▇████▇▇██▇█▇█▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▅▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▁▁▂▂▁▁▂▂▁▂▂▂▂▁▂▂▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step 79\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.98828\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 0.98743\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall 0.97527\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.92813\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.18605\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilver-sweep-1--3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/ykbamlid\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 6 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240704_192039-ykbamlid/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240704_194439-xncxss4h\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-sweep-1--4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/xncxss4h\u001b[0m\n",
            "FOLD 4\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.835 accuracy: 0.566 [after 4 batches]\n",
            "train loss: 0.666 accuracy: 0.677 [after 9 batches]\n",
            "train loss: 0.547 accuracy: 0.745 [after 14 batches]\n",
            "train loss: 0.482 accuracy: 0.784 [after 19 batches]\n",
            "test loss: 1.248 accuracy: 0.451 recall: 1.000 precision: 0.451 f1: 0.621 [after 4 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.205 accuracy: 0.928 [after 4 batches]\n",
            "train loss: 0.219 accuracy: 0.914 [after 9 batches]\n",
            "train loss: 0.231 accuracy: 0.911 [after 14 batches]\n",
            "train loss: 0.242 accuracy: 0.906 [after 19 batches]\n",
            "test loss: 1.600 accuracy: 0.456 recall: 1.000 precision: 0.448 f1: 0.617 [after 4 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.235 accuracy: 0.919 [after 4 batches]\n",
            "train loss: 0.237 accuracy: 0.922 [after 9 batches]\n",
            "train loss: 0.241 accuracy: 0.918 [after 14 batches]\n",
            "train loss: 0.252 accuracy: 0.915 [after 19 batches]\n",
            "test loss: 0.144 accuracy: 0.987 recall: 1.000 precision: 0.969 f1: 0.984 [after 4 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.253 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.235 accuracy: 0.916 [after 9 batches]\n",
            "train loss: 0.243 accuracy: 0.911 [after 14 batches]\n",
            "train loss: 0.251 accuracy: 0.908 [after 19 batches]\n",
            "test loss: 0.155 accuracy: 0.957 recall: 1.000 precision: 0.914 f1: 0.954 [after 4 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.252 accuracy: 0.900 [after 4 batches]\n",
            "train loss: 0.268 accuracy: 0.889 [after 9 batches]\n",
            "train loss: 0.255 accuracy: 0.902 [after 14 batches]\n",
            "train loss: 0.262 accuracy: 0.898 [after 19 batches]\n",
            "test loss: 0.126 accuracy: 0.992 recall: 1.000 precision: 0.985 f1: 0.992 [after 4 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.237 accuracy: 0.913 [after 4 batches]\n",
            "train loss: 0.220 accuracy: 0.920 [after 9 batches]\n",
            "train loss: 0.227 accuracy: 0.914 [after 14 batches]\n",
            "train loss: 0.234 accuracy: 0.910 [after 19 batches]\n",
            "test loss: 0.041 accuracy: 0.996 recall: 0.991 precision: 1.000 f1: 0.995 [after 4 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.195 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.208 accuracy: 0.930 [after 9 batches]\n",
            "train loss: 0.212 accuracy: 0.922 [after 14 batches]\n",
            "train loss: 0.213 accuracy: 0.922 [after 19 batches]\n",
            "test loss: 0.141 accuracy: 1.000 recall: 1.000 precision: 1.000 f1: 1.000 [after 4 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.249 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.222 accuracy: 0.911 [after 9 batches]\n",
            "train loss: 0.230 accuracy: 0.909 [after 14 batches]\n",
            "train loss: 0.218 accuracy: 0.913 [after 19 batches]\n",
            "test loss: 0.262 accuracy: 1.000 recall: 1.000 precision: 1.000 f1: 1.000 [after 4 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.190 accuracy: 0.925 [after 4 batches]\n",
            "train loss: 0.177 accuracy: 0.931 [after 9 batches]\n",
            "train loss: 0.215 accuracy: 0.915 [after 14 batches]\n",
            "train loss: 0.227 accuracy: 0.905 [after 19 batches]\n",
            "test loss: 0.217 accuracy: 0.957 recall: 1.000 precision: 0.921 f1: 0.958 [after 4 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.183 accuracy: 0.931 [after 4 batches]\n",
            "train loss: 0.181 accuracy: 0.934 [after 9 batches]\n",
            "train loss: 0.203 accuracy: 0.922 [after 14 batches]\n",
            "train loss: 0.199 accuracy: 0.922 [after 19 batches]\n",
            "test loss: 0.250 accuracy: 0.943 recall: 1.000 precision: 0.880 f1: 0.934 [after 4 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.180 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.175 accuracy: 0.933 [after 9 batches]\n",
            "train loss: 0.171 accuracy: 0.934 [after 14 batches]\n",
            "train loss: 0.186 accuracy: 0.924 [after 19 batches]\n",
            "test loss: 0.399 accuracy: 0.864 recall: 1.000 precision: 0.769 f1: 0.869 [after 4 batches]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train loss: 0.213 accuracy: 0.909 [after 4 batches]\n",
            "train loss: 0.174 accuracy: 0.927 [after 9 batches]\n",
            "train loss: 0.202 accuracy: 0.906 [after 14 batches]\n",
            "train loss: 0.223 accuracy: 0.902 [after 19 batches]\n",
            "test loss: 0.494 accuracy: 0.550 recall: 0.064 precision: 0.399 f1: 0.106 [after 4 batches]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "train loss: 0.260 accuracy: 0.894 [after 4 batches]\n",
            "train loss: 0.286 accuracy: 0.881 [after 9 batches]\n",
            "train loss: 0.256 accuracy: 0.897 [after 14 batches]\n",
            "train loss: 0.248 accuracy: 0.899 [after 19 batches]\n",
            "test loss: 0.214 accuracy: 0.930 recall: 1.000 precision: 0.861 f1: 0.924 [after 4 batches]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "train loss: 0.145 accuracy: 0.959 [after 4 batches]\n",
            "train loss: 0.151 accuracy: 0.945 [after 9 batches]\n",
            "train loss: 0.160 accuracy: 0.941 [after 14 batches]\n",
            "train loss: 0.198 accuracy: 0.927 [after 19 batches]\n",
            "test loss: 0.029 accuracy: 0.996 recall: 0.993 precision: 1.000 f1: 0.996 [after 4 batches]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "train loss: 0.202 accuracy: 0.934 [after 4 batches]\n",
            "train loss: 0.200 accuracy: 0.942 [after 9 batches]\n",
            "train loss: 0.205 accuracy: 0.933 [after 14 batches]\n",
            "train loss: 0.234 accuracy: 0.923 [after 19 batches]\n",
            "test loss: 0.029 accuracy: 0.991 recall: 0.975 precision: 1.000 f1: 0.987 [after 4 batches]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "train loss: 0.227 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.245 accuracy: 0.889 [after 9 batches]\n",
            "train loss: 0.243 accuracy: 0.899 [after 14 batches]\n",
            "train loss: 0.235 accuracy: 0.897 [after 19 batches]\n",
            "test loss: 0.274 accuracy: 0.856 recall: 1.000 precision: 0.762 f1: 0.864 [after 4 batches]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "train loss: 0.259 accuracy: 0.894 [after 4 batches]\n",
            "train loss: 0.239 accuracy: 0.905 [after 9 batches]\n",
            "train loss: 0.231 accuracy: 0.908 [after 14 batches]\n",
            "train loss: 0.214 accuracy: 0.918 [after 19 batches]\n",
            "test loss: 0.165 accuracy: 0.984 recall: 1.000 precision: 0.967 f1: 0.983 [after 4 batches]\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "train loss: 0.176 accuracy: 0.922 [after 4 batches]\n",
            "train loss: 0.180 accuracy: 0.917 [after 9 batches]\n",
            "train loss: 0.189 accuracy: 0.916 [after 14 batches]\n",
            "train loss: 0.205 accuracy: 0.909 [after 19 batches]\n",
            "test loss: 0.361 accuracy: 0.709 recall: 1.000 precision: 0.602 f1: 0.750 [after 4 batches]\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "train loss: 0.262 accuracy: 0.887 [after 4 batches]\n",
            "train loss: 0.230 accuracy: 0.906 [after 9 batches]\n",
            "train loss: 0.220 accuracy: 0.907 [after 14 batches]\n",
            "train loss: 0.208 accuracy: 0.916 [after 19 batches]\n",
            "test loss: 0.218 accuracy: 0.957 recall: 1.000 precision: 0.920 f1: 0.958 [after 4 batches]\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "train loss: 0.160 accuracy: 0.947 [after 4 batches]\n",
            "train loss: 0.187 accuracy: 0.928 [after 9 batches]\n",
            "train loss: 0.180 accuracy: 0.923 [after 14 batches]\n",
            "train loss: 0.187 accuracy: 0.919 [after 19 batches]\n",
            "test loss: 0.215 accuracy: 0.881 recall: 0.992 precision: 0.806 f1: 0.887 [after 4 batches]\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "train loss: 0.188 accuracy: 0.909 [after 4 batches]\n",
            "train loss: 0.168 accuracy: 0.925 [after 9 batches]\n",
            "train loss: 0.189 accuracy: 0.919 [after 14 batches]\n",
            "train loss: 0.196 accuracy: 0.916 [after 19 batches]\n",
            "test loss: 0.086 accuracy: 0.996 recall: 1.000 precision: 0.990 f1: 0.995 [after 4 batches]\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "train loss: 0.149 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.171 accuracy: 0.927 [after 9 batches]\n",
            "train loss: 0.166 accuracy: 0.931 [after 14 batches]\n",
            "train loss: 0.163 accuracy: 0.934 [after 19 batches]\n",
            "test loss: 0.341 accuracy: 0.882 recall: 1.000 precision: 0.791 f1: 0.882 [after 4 batches]\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "train loss: 0.177 accuracy: 0.941 [after 4 batches]\n",
            "train loss: 0.210 accuracy: 0.930 [after 9 batches]\n",
            "train loss: 0.227 accuracy: 0.914 [after 14 batches]\n",
            "train loss: 0.211 accuracy: 0.920 [after 19 batches]\n",
            "test loss: 0.096 accuracy: 1.000 recall: 1.000 precision: 1.000 f1: 1.000 [after 4 batches]\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "train loss: 0.196 accuracy: 0.931 [after 4 batches]\n",
            "train loss: 0.183 accuracy: 0.922 [after 9 batches]\n",
            "train loss: 0.165 accuracy: 0.932 [after 14 batches]\n",
            "train loss: 0.184 accuracy: 0.927 [after 19 batches]\n",
            "test loss: 0.385 accuracy: 0.629 recall: 1.000 precision: 0.545 f1: 0.704 [after 4 batches]\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "train loss: 0.136 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.182 accuracy: 0.930 [after 9 batches]\n",
            "train loss: 0.177 accuracy: 0.928 [after 14 batches]\n",
            "train loss: 0.171 accuracy: 0.930 [after 19 batches]\n",
            "test loss: 0.063 accuracy: 0.987 recall: 0.985 precision: 0.992 f1: 0.988 [after 4 batches]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁▁█▇████▇▇▆▂▇██▆█▄▇▆█▆█▃█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 ▅▅███████▇▇▁▇██▇█▆█▇█▇█▆█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision ▂▂█▇████▇▇▅▁▆██▅█▃▇▆█▆█▃█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall ███████████▁█████████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▄▇▇▇▇▇▇▇▇█▇▇█▇▇███▇▇███▇▇▇▇▇▇███▇██▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▅▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▂▁▂▂▂▂▂▁▂▂▁▁▁▂▁▁▂▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step 99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.98717\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 0.98846\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision 0.99219\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall 0.98529\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.93047\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.17099\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilver-sweep-1--4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/xncxss4h\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 8 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240704_194439-xncxss4h/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240704_201436-ox9d5d0g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-sweep-1--5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/ox9d5d0g\u001b[0m\n",
            "FOLD 5\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.878 accuracy: 0.556 [after 4 batches]\n",
            "train loss: 0.711 accuracy: 0.644 [after 9 batches]\n",
            "train loss: 0.588 accuracy: 0.719 [after 14 batches]\n",
            "train loss: 0.511 accuracy: 0.761 [after 19 batches]\n",
            "test loss: 0.788 accuracy: 0.549 recall: 0.000 precision: 0.000 f1: 0.000 [after 4 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.317 accuracy: 0.869 [after 4 batches]\n",
            "train loss: 0.286 accuracy: 0.884 [after 9 batches]\n",
            "train loss: 0.260 accuracy: 0.900 [after 14 batches]\n",
            "train loss: 0.256 accuracy: 0.905 [after 19 batches]\n",
            "test loss: 2.381 accuracy: 0.628 recall: 1.000 precision: 0.554 f1: 0.712 [after 4 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.409 accuracy: 0.834 [after 4 batches]\n",
            "train loss: 0.341 accuracy: 0.861 [after 9 batches]\n",
            "train loss: 0.332 accuracy: 0.870 [after 14 batches]\n",
            "train loss: 0.313 accuracy: 0.877 [after 19 batches]\n",
            "test loss: 0.214 accuracy: 0.926 recall: 1.000 precision: 0.853 f1: 0.919 [after 4 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.281 accuracy: 0.894 [after 4 batches]\n",
            "train loss: 0.251 accuracy: 0.908 [after 9 batches]\n",
            "train loss: 0.235 accuracy: 0.915 [after 14 batches]\n",
            "train loss: 0.242 accuracy: 0.909 [after 19 batches]\n",
            "test loss: 0.323 accuracy: 0.899 recall: 1.000 precision: 0.815 f1: 0.898 [after 4 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.247 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.227 accuracy: 0.922 [after 9 batches]\n",
            "train loss: 0.230 accuracy: 0.915 [after 14 batches]\n",
            "train loss: 0.238 accuracy: 0.913 [after 19 batches]\n",
            "test loss: 0.038 accuracy: 0.996 recall: 0.992 precision: 1.000 f1: 0.996 [after 4 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.202 accuracy: 0.913 [after 4 batches]\n",
            "train loss: 0.208 accuracy: 0.917 [after 9 batches]\n",
            "train loss: 0.236 accuracy: 0.914 [after 14 batches]\n",
            "train loss: 0.238 accuracy: 0.913 [after 19 batches]\n",
            "test loss: 0.083 accuracy: 0.987 recall: 0.968 precision: 1.000 f1: 0.984 [after 4 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.261 accuracy: 0.913 [after 4 batches]\n",
            "train loss: 0.223 accuracy: 0.923 [after 9 batches]\n",
            "train loss: 0.233 accuracy: 0.914 [after 14 batches]\n",
            "train loss: 0.224 accuracy: 0.913 [after 19 batches]\n",
            "test loss: 0.027 accuracy: 0.996 recall: 0.992 precision: 1.000 f1: 0.996 [after 4 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.229 accuracy: 0.922 [after 4 batches]\n",
            "train loss: 0.260 accuracy: 0.903 [after 9 batches]\n",
            "train loss: 0.253 accuracy: 0.902 [after 14 batches]\n",
            "train loss: 0.258 accuracy: 0.898 [after 19 batches]\n",
            "test loss: 0.116 accuracy: 0.996 recall: 1.000 precision: 0.991 f1: 0.996 [after 4 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.216 accuracy: 0.909 [after 4 batches]\n",
            "train loss: 0.226 accuracy: 0.909 [after 9 batches]\n",
            "train loss: 0.231 accuracy: 0.908 [after 14 batches]\n",
            "train loss: 0.220 accuracy: 0.913 [after 19 batches]\n",
            "test loss: 0.320 accuracy: 0.893 recall: 1.000 precision: 0.815 f1: 0.897 [after 4 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.159 accuracy: 0.956 [after 4 batches]\n",
            "train loss: 0.180 accuracy: 0.938 [after 9 batches]\n",
            "train loss: 0.183 accuracy: 0.938 [after 14 batches]\n",
            "train loss: 0.194 accuracy: 0.935 [after 19 batches]\n",
            "test loss: 0.062 accuracy: 0.992 recall: 0.984 precision: 1.000 f1: 0.992 [after 4 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.168 accuracy: 0.941 [after 4 batches]\n",
            "train loss: 0.177 accuracy: 0.934 [after 9 batches]\n",
            "train loss: 0.195 accuracy: 0.928 [after 14 batches]\n",
            "train loss: 0.202 accuracy: 0.925 [after 19 batches]\n",
            "test loss: 0.071 accuracy: 0.987 recall: 0.974 precision: 1.000 f1: 0.987 [after 4 batches]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train loss: 0.184 accuracy: 0.941 [after 4 batches]\n",
            "train loss: 0.164 accuracy: 0.950 [after 9 batches]\n",
            "train loss: 0.202 accuracy: 0.935 [after 14 batches]\n",
            "train loss: 0.184 accuracy: 0.944 [after 19 batches]\n",
            "test loss: 0.083 accuracy: 0.992 recall: 0.984 precision: 1.000 f1: 0.992 [after 4 batches]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "train loss: 0.186 accuracy: 0.934 [after 4 batches]\n",
            "train loss: 0.188 accuracy: 0.928 [after 9 batches]\n",
            "train loss: 0.181 accuracy: 0.932 [after 14 batches]\n",
            "train loss: 0.185 accuracy: 0.934 [after 19 batches]\n",
            "test loss: 1.094 accuracy: 0.728 recall: 0.981 precision: 0.636 f1: 0.764 [after 4 batches]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "train loss: 0.290 accuracy: 0.866 [after 4 batches]\n",
            "train loss: 0.287 accuracy: 0.878 [after 9 batches]\n",
            "train loss: 0.284 accuracy: 0.878 [after 14 batches]\n",
            "train loss: 0.261 accuracy: 0.891 [after 19 batches]\n",
            "test loss: 0.042 accuracy: 1.000 recall: 1.000 precision: 1.000 f1: 1.000 [after 4 batches]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "train loss: 0.209 accuracy: 0.934 [after 4 batches]\n",
            "train loss: 0.197 accuracy: 0.938 [after 9 batches]\n",
            "train loss: 0.214 accuracy: 0.926 [after 14 batches]\n",
            "train loss: 0.197 accuracy: 0.934 [after 19 batches]\n",
            "test loss: 0.151 accuracy: 0.920 recall: 1.000 precision: 0.846 f1: 0.916 [after 4 batches]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "train loss: 0.195 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.206 accuracy: 0.928 [after 9 batches]\n",
            "train loss: 0.196 accuracy: 0.932 [after 14 batches]\n",
            "train loss: 0.183 accuracy: 0.938 [after 19 batches]\n",
            "test loss: 0.457 accuracy: 0.907 recall: 1.000 precision: 0.826 f1: 0.904 [after 4 batches]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "train loss: 0.201 accuracy: 0.909 [after 4 batches]\n",
            "train loss: 0.207 accuracy: 0.920 [after 9 batches]\n",
            "train loss: 0.226 accuracy: 0.919 [after 14 batches]\n",
            "train loss: 0.241 accuracy: 0.909 [after 19 batches]\n",
            "test loss: 0.387 accuracy: 0.826 recall: 0.627 precision: 1.000 f1: 0.768 [after 4 batches]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁▂▇▆████▆███▄█▇▇▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 ▁▆▇▇████▇███▆█▇▇▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision ▁▅▇▇████▇███▅█▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall ▁███████████████▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▅▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████▇▇█▇███▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▆▄▂▂▃▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▁▂▁▁▁▁▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step 67\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.82645\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 0.76767\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall 0.62667\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.90859\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.24093\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilver-sweep-1--5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/ox9d5d0g\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 6 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240704_201436-ox9d5d0g/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240704_203454-pod1qm2z\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-sweep-1--6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/pod1qm2z\u001b[0m\n",
            "FOLD 6\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.759 accuracy: 0.547 [after 4 batches]\n",
            "train loss: 0.643 accuracy: 0.652 [after 9 batches]\n",
            "train loss: 0.548 accuracy: 0.725 [after 14 batches]\n",
            "train loss: 0.475 accuracy: 0.768 [after 19 batches]\n",
            "test loss: 0.986 accuracy: 0.564 recall: 0.000 precision: 0.000 f1: 0.000 [after 4 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.212 accuracy: 0.919 [after 4 batches]\n",
            "train loss: 0.280 accuracy: 0.891 [after 9 batches]\n",
            "train loss: 0.271 accuracy: 0.901 [after 14 batches]\n",
            "train loss: 0.270 accuracy: 0.902 [after 19 batches]\n",
            "test loss: 0.411 accuracy: 0.829 recall: 0.805 precision: 0.816 f1: 0.810 [after 4 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.283 accuracy: 0.881 [after 4 batches]\n",
            "train loss: 0.250 accuracy: 0.895 [after 9 batches]\n",
            "train loss: 0.236 accuracy: 0.906 [after 14 batches]\n",
            "train loss: 0.226 accuracy: 0.908 [after 19 batches]\n",
            "test loss: 0.326 accuracy: 0.912 recall: 0.804 precision: 1.000 f1: 0.890 [after 4 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.184 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.176 accuracy: 0.945 [after 9 batches]\n",
            "train loss: 0.179 accuracy: 0.945 [after 14 batches]\n",
            "train loss: 0.190 accuracy: 0.941 [after 19 batches]\n",
            "test loss: 0.277 accuracy: 0.912 recall: 0.806 precision: 1.000 f1: 0.892 [after 4 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.185 accuracy: 0.938 [after 4 batches]\n",
            "train loss: 0.171 accuracy: 0.944 [after 9 batches]\n",
            "train loss: 0.196 accuracy: 0.935 [after 14 batches]\n",
            "train loss: 0.201 accuracy: 0.931 [after 19 batches]\n",
            "test loss: 0.294 accuracy: 0.912 recall: 0.810 precision: 1.000 f1: 0.893 [after 4 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.163 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.167 accuracy: 0.948 [after 9 batches]\n",
            "train loss: 0.179 accuracy: 0.943 [after 14 batches]\n",
            "train loss: 0.181 accuracy: 0.941 [after 19 batches]\n",
            "test loss: 0.296 accuracy: 0.912 recall: 0.808 precision: 1.000 f1: 0.892 [after 4 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.174 accuracy: 0.941 [after 4 batches]\n",
            "train loss: 0.222 accuracy: 0.930 [after 9 batches]\n",
            "train loss: 0.203 accuracy: 0.939 [after 14 batches]\n",
            "train loss: 0.204 accuracy: 0.938 [after 19 batches]\n",
            "test loss: 0.190 accuracy: 0.882 recall: 0.849 precision: 0.889 f1: 0.867 [after 4 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.165 accuracy: 0.947 [after 4 batches]\n",
            "train loss: 0.191 accuracy: 0.939 [after 9 batches]\n",
            "train loss: 0.193 accuracy: 0.938 [after 14 batches]\n",
            "train loss: 0.188 accuracy: 0.938 [after 19 batches]\n",
            "test loss: 0.314 accuracy: 0.903 recall: 0.783 precision: 1.000 f1: 0.878 [after 4 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.179 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.182 accuracy: 0.936 [after 9 batches]\n",
            "train loss: 0.204 accuracy: 0.929 [after 14 batches]\n",
            "train loss: 0.214 accuracy: 0.923 [after 19 batches]\n",
            "test loss: 0.283 accuracy: 0.912 recall: 0.795 precision: 1.000 f1: 0.884 [after 4 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.157 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.172 accuracy: 0.936 [after 9 batches]\n",
            "train loss: 0.165 accuracy: 0.938 [after 14 batches]\n",
            "train loss: 0.166 accuracy: 0.939 [after 19 batches]\n",
            "test loss: 0.267 accuracy: 0.922 recall: 0.829 precision: 1.000 f1: 0.902 [after 4 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.155 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.171 accuracy: 0.941 [after 9 batches]\n",
            "train loss: 0.175 accuracy: 0.941 [after 14 batches]\n",
            "train loss: 0.180 accuracy: 0.939 [after 19 batches]\n",
            "test loss: 0.296 accuracy: 0.902 recall: 0.777 precision: 1.000 f1: 0.873 [after 4 batches]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train loss: 0.144 accuracy: 0.947 [after 4 batches]\n",
            "train loss: 0.180 accuracy: 0.936 [after 9 batches]\n",
            "train loss: 0.194 accuracy: 0.931 [after 14 batches]\n",
            "train loss: 0.207 accuracy: 0.924 [after 19 batches]\n",
            "test loss: 0.395 accuracy: 0.869 recall: 0.783 precision: 0.927 f1: 0.847 [after 4 batches]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "train loss: 0.182 accuracy: 0.941 [after 4 batches]\n",
            "train loss: 0.175 accuracy: 0.941 [after 9 batches]\n",
            "train loss: 0.155 accuracy: 0.951 [after 14 batches]\n",
            "train loss: 0.164 accuracy: 0.947 [after 19 batches]\n",
            "test loss: 0.289 accuracy: 0.917 recall: 0.815 precision: 1.000 f1: 0.894 [after 4 batches]\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "train loss: 0.210 accuracy: 0.919 [after 4 batches]\n",
            "train loss: 0.169 accuracy: 0.939 [after 9 batches]\n",
            "train loss: 0.183 accuracy: 0.943 [after 14 batches]\n",
            "train loss: 0.189 accuracy: 0.940 [after 19 batches]\n",
            "test loss: 0.343 accuracy: 0.895 recall: 0.772 precision: 1.000 f1: 0.871 [after 4 batches]\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "train loss: 0.255 accuracy: 0.909 [after 4 batches]\n",
            "train loss: 0.205 accuracy: 0.933 [after 9 batches]\n",
            "train loss: 0.180 accuracy: 0.941 [after 14 batches]\n",
            "train loss: 0.176 accuracy: 0.944 [after 19 batches]\n",
            "test loss: 0.311 accuracy: 0.902 recall: 0.782 precision: 1.000 f1: 0.877 [after 4 batches]\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "train loss: 0.156 accuracy: 0.956 [after 4 batches]\n",
            "train loss: 0.188 accuracy: 0.950 [after 9 batches]\n",
            "train loss: 0.193 accuracy: 0.948 [after 14 batches]\n",
            "train loss: 0.181 accuracy: 0.952 [after 19 batches]\n",
            "test loss: 0.472 accuracy: 0.829 recall: 0.795 precision: 0.825 f1: 0.809 [after 4 batches]\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "train loss: 0.367 accuracy: 0.816 [after 4 batches]\n",
            "train loss: 0.300 accuracy: 0.861 [after 9 batches]\n",
            "train loss: 0.279 accuracy: 0.877 [after 14 batches]\n",
            "train loss: 0.257 accuracy: 0.891 [after 19 batches]\n",
            "test loss: 0.365 accuracy: 0.845 recall: 0.779 precision: 0.876 f1: 0.821 [after 4 batches]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▁▂▂▃▃▄▄▅▅▅▆▆▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁▆████▇████▇█▇█▆▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 ▁▇█████████████▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision ▁▇████▇████▇███▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall ▁██████▇██▇▇█▇▇█▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▃▅▇▇▇▇██████████████████████████▇████▆▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▇▅▃▂▃▂▁▁▂▁▂▁▁▁▂▂▂▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▃▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step 67\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.84487\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 0.82078\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision 0.87565\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall 0.77872\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.89062\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.257\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilver-sweep-1--6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/pod1qm2z\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 7 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240704_203454-pod1qm2z/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240704_205525-k1d74m1u\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msilver-sweep-1--7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/k1d74m1u\u001b[0m\n",
            "FOLD 7\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.902 accuracy: 0.491 [after 4 batches]\n",
            "train loss: 0.810 accuracy: 0.531 [after 9 batches]\n",
            "train loss: 0.714 accuracy: 0.601 [after 14 batches]\n",
            "train loss: 0.609 accuracy: 0.670 [after 19 batches]\n",
            "test loss: 1.127 accuracy: 0.549 recall: 0.000 precision: 0.000 f1: 0.000 [after 4 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.272 accuracy: 0.900 [after 4 batches]\n",
            "train loss: 0.244 accuracy: 0.919 [after 9 batches]\n",
            "train loss: 0.231 accuracy: 0.925 [after 14 batches]\n",
            "train loss: 0.230 accuracy: 0.928 [after 19 batches]\n",
            "test loss: 0.403 accuracy: 0.889 recall: 0.756 precision: 1.000 f1: 0.859 [after 4 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.261 accuracy: 0.906 [after 4 batches]\n",
            "train loss: 0.271 accuracy: 0.894 [after 9 batches]\n",
            "train loss: 0.252 accuracy: 0.906 [after 14 batches]\n",
            "train loss: 0.261 accuracy: 0.898 [after 19 batches]\n",
            "test loss: 0.361 accuracy: 0.739 recall: 0.765 precision: 0.666 f1: 0.711 [after 4 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.170 accuracy: 0.950 [after 4 batches]\n",
            "train loss: 0.190 accuracy: 0.947 [after 9 batches]\n",
            "train loss: 0.199 accuracy: 0.943 [after 14 batches]\n",
            "train loss: 0.203 accuracy: 0.941 [after 19 batches]\n",
            "test loss: 0.469 accuracy: 0.878 recall: 0.798 precision: 0.922 f1: 0.856 [after 4 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.199 accuracy: 0.928 [after 4 batches]\n",
            "train loss: 0.173 accuracy: 0.939 [after 9 batches]\n",
            "train loss: 0.166 accuracy: 0.942 [after 14 batches]\n",
            "train loss: 0.168 accuracy: 0.944 [after 19 batches]\n",
            "test loss: 0.452 accuracy: 0.871 recall: 0.693 precision: 1.000 f1: 0.812 [after 4 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.350 accuracy: 0.894 [after 4 batches]\n",
            "train loss: 0.275 accuracy: 0.919 [after 9 batches]\n",
            "train loss: 0.262 accuracy: 0.914 [after 14 batches]\n",
            "train loss: 0.247 accuracy: 0.916 [after 19 batches]\n",
            "test loss: 0.771 accuracy: 0.728 recall: 0.400 precision: 1.000 f1: 0.565 [after 4 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.247 accuracy: 0.916 [after 4 batches]\n",
            "train loss: 0.207 accuracy: 0.933 [after 9 batches]\n",
            "train loss: 0.191 accuracy: 0.936 [after 14 batches]\n",
            "train loss: 0.199 accuracy: 0.933 [after 19 batches]\n",
            "test loss: 0.390 accuracy: 0.888 recall: 0.743 precision: 1.000 f1: 0.848 [after 4 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.175 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.168 accuracy: 0.945 [after 9 batches]\n",
            "train loss: 0.165 accuracy: 0.947 [after 14 batches]\n",
            "train loss: 0.172 accuracy: 0.945 [after 19 batches]\n",
            "test loss: 0.377 accuracy: 0.904 recall: 0.775 precision: 1.000 f1: 0.870 [after 4 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.171 accuracy: 0.941 [after 4 batches]\n",
            "train loss: 0.189 accuracy: 0.934 [after 9 batches]\n",
            "train loss: 0.182 accuracy: 0.938 [after 14 batches]\n",
            "train loss: 0.166 accuracy: 0.944 [after 19 batches]\n",
            "test loss: 0.473 accuracy: 0.877 recall: 0.727 precision: 1.000 f1: 0.838 [after 4 batches]\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "train loss: 0.105 accuracy: 0.963 [after 4 batches]\n",
            "train loss: 0.140 accuracy: 0.952 [after 9 batches]\n",
            "train loss: 0.157 accuracy: 0.946 [after 14 batches]\n",
            "train loss: 0.170 accuracy: 0.939 [after 19 batches]\n",
            "test loss: 0.413 accuracy: 0.801 recall: 0.544 precision: 1.000 f1: 0.698 [after 4 batches]\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "train loss: 0.220 accuracy: 0.909 [after 4 batches]\n",
            "train loss: 0.184 accuracy: 0.928 [after 9 batches]\n",
            "train loss: 0.178 accuracy: 0.933 [after 14 batches]\n",
            "train loss: 0.173 accuracy: 0.935 [after 19 batches]\n",
            "test loss: 0.452 accuracy: 0.881 recall: 0.733 precision: 1.000 f1: 0.845 [after 4 batches]\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "train loss: 0.162 accuracy: 0.944 [after 4 batches]\n",
            "train loss: 0.165 accuracy: 0.941 [after 9 batches]\n",
            "train loss: 0.148 accuracy: 0.947 [after 14 batches]\n",
            "train loss: 0.136 accuracy: 0.950 [after 19 batches]\n",
            "test loss: 0.928 accuracy: 0.819 recall: 0.600 precision: 1.000 f1: 0.746 [after 4 batches]\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "train loss: 0.109 accuracy: 0.956 [after 4 batches]\n",
            "train loss: 0.133 accuracy: 0.948 [after 9 batches]\n",
            "train loss: 0.137 accuracy: 0.950 [after 14 batches]\n",
            "train loss: 0.138 accuracy: 0.952 [after 19 batches]\n",
            "test loss: 0.686 accuracy: 0.819 recall: 0.572 precision: 1.000 f1: 0.723 [after 4 batches]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▂▃▃▄▅▅▆▆▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁█▅▇▇▅██▇▆█▆▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 ▁█▇██▆███▇█▇▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision ▁█▆▇█████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall ▁███▇▅██▇▆▇▆▆\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▁▂▃▄▇▇▇▇▇▇██████▇▇▇▇███████████▇▇███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▇▆▅▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 13\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step 51\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.81864\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 0.72283\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall 0.57193\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.95234\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.13816\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilver-sweep-1--7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/k1d74m1u\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 5 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240704_205525-k1d74m1u/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240704_211124-51i3330j\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Resuming run \u001b[33msilver-sweep-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/sweeps/5oq5gka9\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/51i3330j\u001b[0m\n",
            "Test_accuracy:\n",
            "  Average: 89.63% (+/- 6.60%)\n",
            "Test_recall:\n",
            "  Average: 87.48% (+/- 9.78%)\n",
            "Test_precision:\n",
            "  Average: 80.53% (+/- 14.77%)\n",
            "Test_f1_score:\n",
            "  Average: 98.11% (+/- 4.31%)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                fold ▁▂▃▅▆▇█▁▂▃▅▆▇█▁▂▃▅▆▇█▁▂▃▅▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  fold_test_accuracy ▄▅██▁▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  fold_test_f1_score █████▁█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: fold_test_precision ▅▆██▂▅▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    fold_test_recall ▆▆██▂▄▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                fold 7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  fold_test_accuracy 0.81864\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  fold_test_f1_score 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: fold_test_precision 0.57193\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    fold_test_recall 0.72283\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msilver-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/51i3330j\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240704_211124-51i3330j/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n",
            "2024-07-04 21:11:38,688 - wandb.wandb_agent - INFO - Cleaning up finished run: 51i3330j\n",
            "2024-07-04 21:11:38,886 - wandb.wandb_agent - INFO - Agent received command: exit\n",
            "2024-07-04 21:11:38,886 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}