{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dftDiCQg3vYy"
      },
      "source": [
        "# <font color='#4C5FDA'>**Breast Cancer Detection Based on CNNs Using Thermal Imaging** </font>\n",
        "\n",
        "Original paper by Juan Pablo Zuluaga, Zeina Al Masry, Khaled Benaggoune, Safa Meraghni & Noureddine Zerhouni: [A CNN-based methodology for breast cancer diagnosis using thermal images](https://www.tandfonline.com/doi/full/10.1080/21681163.2020.1824685)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uraq36CkXB1T",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Instalar paquetes necesarios**\n",
        "\n",
        "%%capture\n",
        "! pip install torchmetrics\n",
        "! pip install wandb -Uq\n",
        "# ! pip install onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#ECA702'>**Clonamos nuestro repo**</font>\n",
        "\n",
        "Esto con el fin de traer todos los .py para poder entrenar 'localmente' en Colab y registrar las métricas en wandb."
      ],
      "metadata": {
        "id": "3eUcjX2Lv5g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/gpintoruiz/Thermal-Imaging-Breast-Cancer-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miS2W9Tdwbxq",
        "outputId": "5886cc4f-e0e4-40bb-e412-bc5b800c0930"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Thermal-Imaging-Breast-Cancer-Detection'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "remote: Counting objects: 100% (121/121), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 121 (delta 57), reused 70 (delta 24), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (121/121), 2.27 MiB | 16.76 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Thermal-Imaging-Breast-Cancer-Detection/notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMuOAySxx1Z1",
        "outputId": "49d2fbeb-1083-4547-d477-7de805fe5957"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssFb9A5GyA_u",
        "outputId": "76cb4a4a-c214-4122-acd8-a524bc925684"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01-gpr-data-exploration-cv2.ipynb  1.00-gpr-xception-from-scratch.ipynb  utils.py\n",
            "0.01-gpr-data-exploration-pil.ipynb  make_dataset.py                       validation.py\n",
            "0.02-gpr-experiments-base.ipynb      test.py                               xception-one-run.yaml\n",
            "0.03-gpr-initial-experiment.ipynb    train_one_run.py                      xception.py\n",
            "0.04-gpr-colab-experiments.ipynb     train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkrHeEps3vY3"
      },
      "source": [
        "## <font color='#ECA702'>**Configuración inicial para conectarnos con Kaggle**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJFg6k1x3vY5"
      },
      "source": [
        "1. Instalamos kaggle. Para poder usar comandos de Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hwqionQb3vY6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP3nl2Et3vY7"
      },
      "source": [
        "Subimos nuestro token de autenticación de Kaggle (si estamos en colab, sino colocarlo en la carpeta del proyecto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARP6wZsb3vY8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0VPkGso3vY9"
      },
      "source": [
        "1. Creamos los directorios de Kaggle\n",
        "2. Copiamos nuestro token en .kaggle\n",
        "3. Con `chmod 600` establecemos los permitos del token en 600, es decir, que solo yo tengo permisos de lectura y escritura sobre el archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ed2nCVTu3vY-"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UhQ_SI9x3vZA"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGkGIazz3vZB"
      },
      "source": [
        "## <font color='#ECA702'>**Carga del dataset**</font>\n",
        "\n",
        "Traemos el dataset [Thermal Images for Breast Cancer Diagnosis DMR-IR](https://www.kaggle.com/datasets/asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir) desde kaggle.\n",
        "\n",
        "This dataset is a methodology for breast disease computer-aided diagnosis using dynamic thermography. The thermal images for breast tumors are classified according to DMR-IR standards.\n",
        "\n",
        "Two types of tumors are classified in this dataset one is benign another is malignant.\n",
        "- Benign: This type of tumor is usually well-defined and round or oval in shape. (non-cancerous tumor)\n",
        "- Malignant: This type of tumor is usually poorly defined and irregular with lobules. (cancerous tumor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "lmT0aOvG3vZD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! kaggle datasets download -d asdeepak/thermal-images-for-breast-cancer-diagnosis-dmrir\n",
        "! unzip thermal-images-for-breast-cancer-diagnosis-dmrir.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QToIa8zB3vZE"
      },
      "source": [
        "Después de descargar los datos. Debemos entender la estructura de las carpetas para poder trabajar con ellas de una mejor manera.\n",
        "1. La carpeta principal `Imagens e Matrizes da Tese de Thiago Alves Elias da Silva` son todos los datos `data`.\n",
        "2. La carpeta `12 Novos Casos de Testes` la podemos tomar como nuestro conjunto de prueba (`test`).\n",
        "3. Mientras que la carpeta `Desenvolvimento da Metodologia` será nuestro conjunto de entrenamiento (`train`).\n",
        "\n",
        "Luego dentro de nuestras carpetas de `train` y `test` encontramos dos categorías `DOENTES`y `SAUDAтХа├╝VEIS` o SAUDÁVEI. Los primeros son los casos malignos y los segundos benignos.\n",
        "\n",
        "Dentro de cada una de las carpetas de pacientes saludables y enfermos se encuentran carpetas con números, cada número representa un paciente. Y para cada paciente tendremos dos carpetas más, una para las imágenes **segmentadas** en escala de grises y la otra para la matrix o mapa de calor.\n",
        "\n",
        "Algo bueno de este dataset es que ya está dividido por pacientes, es decir, no tendremos imagenes del mismo paciente en el conjunto de entrenamiento y testeo. Por lo tanto, vamos a entrenar con N pacientes, y testear con K pacientes, que no son los mismos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='#ECA702'>**Inicializamos el agende de wandb**</font>"
      ],
      "metadata": {
        "id": "5YTKbsdDyqSj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#52F17F'>**1. Nos logeamos en nuestra cuenta**</font>"
      ],
      "metadata": {
        "id": "nIskv2fHy4Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "St3agN3Rypzq",
        "outputId": "ed0e999d-b990-416a-c79d-fc718b01ad00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='#52F17F'>**2. Hacemos call del agente**</font>\n"
      ],
      "metadata": {
        "id": "w0r-E8Ufy9TQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El sweep que estoy probando acá es el [siguiente](https://github.com/gpintoruiz/Thermal-Imaging-Breast-Cancer-Detection/blob/main/notebooks/xception-one-run.yaml). Se pueden cambiar los parámetros a probar como tú quieras de acuerdo con la [documentación](https://docs.wandb.ai/guides/sweeps/define-sweep-configuration) (recomiendo solo cambiar la arquitectura para que las comparaciones entre modelos sean equivalentes).\n",
        "\n",
        "Si no tienes ni idea qué es un sweep mira el siguiente [tutorial](https://www.youtube.com/watch?v=9zrmUIlScdY&t=1361s&ab_channel=Weights%26Biases).\n",
        "\n",
        "El comando `--count` sirve para decirle al agente cuántos runs hacer, aplica especialmente cuando el método del sweep es `bayes` o `random`\n"
      ],
      "metadata": {
        "id": "LxtyncVoCVL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wandb agent aiuis/dip-project/epbt9jh6 --count 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpG6dTZdy0R3",
        "outputId": "c4134fe9-6578-45dc-dc12-6c2d3cbc8210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
            "2024-06-09 18:36:23,481 - wandb.wandb_agent - INFO - Running runs: []\n",
            "2024-06-09 18:36:23,755 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2024-06-09 18:36:23,755 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tarchitecture: xception\n",
            "\taugmented: True\n",
            "\tbatch_size: 8\n",
            "\tfold: 3\n",
            "\tlearning_rate: 0.0015528833190894193\n",
            "\tnormalize: False\n",
            "\toptimizer: adam\n",
            "\tresize: 300\n",
            "2024-06-09 18:36:23,758 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train_one_run.py --architecture=xception --augmented=True --batch_size=8 --fold=3 --learning_rate=0.0015528833190894193 --normalize=False --optimizer=adam --resize=300\n",
            "2024-06-09 18:36:28,773 - wandb.wandb_agent - INFO - Running runs: ['psadoyj7']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgpintoruiz\u001b[0m (\u001b[33maiuis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240609_183633-psadoyj7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdandy-sweep-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/sweeps/epbt9jh6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/psadoyj7\u001b[0m\n",
            "FOLD 3\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "train loss: 0.802 accuracy: 0.492 [after 32 batches]\n",
            "train loss: 0.763 accuracy: 0.504 [after 65 batches]\n",
            "train loss: 0.746 accuracy: 0.514 [after 98 batches]\n",
            "train loss: 0.735 accuracy: 0.498 [after 131 batches]\n",
            "val loss: 0.705 accuracy: 0.500 [after 30 batches]\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "train loss: 0.701 accuracy: 0.477 [after 32 batches]\n",
            "train loss: 0.693 accuracy: 0.545 [after 65 batches]\n",
            "train loss: 0.703 accuracy: 0.540 [after 98 batches]\n",
            "train loss: 0.705 accuracy: 0.524 [after 131 batches]\n",
            "val loss: 0.740 accuracy: 0.663 [after 30 batches]\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "train loss: 0.698 accuracy: 0.504 [after 32 batches]\n",
            "train loss: 0.688 accuracy: 0.500 [after 65 batches]\n",
            "train loss: 0.695 accuracy: 0.508 [after 98 batches]\n",
            "train loss: 0.695 accuracy: 0.510 [after 131 batches]\n",
            "val loss: 0.734 accuracy: 0.542 [after 30 batches]\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "train loss: 0.679 accuracy: 0.568 [after 32 batches]\n",
            "train loss: 0.684 accuracy: 0.585 [after 65 batches]\n",
            "train loss: 0.685 accuracy: 0.576 [after 98 batches]\n",
            "train loss: 0.680 accuracy: 0.584 [after 131 batches]\n",
            "val loss: 0.633 accuracy: 0.708 [after 30 batches]\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "train loss: 0.685 accuracy: 0.614 [after 32 batches]\n",
            "train loss: 0.685 accuracy: 0.581 [after 65 batches]\n",
            "train loss: 0.687 accuracy: 0.577 [after 98 batches]\n",
            "train loss: 0.692 accuracy: 0.562 [after 131 batches]\n",
            "val loss: 0.666 accuracy: 0.646 [after 30 batches]\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "train loss: 0.674 accuracy: 0.606 [after 32 batches]\n",
            "train loss: 0.678 accuracy: 0.597 [after 65 batches]\n",
            "train loss: 0.689 accuracy: 0.585 [after 98 batches]\n",
            "train loss: 0.683 accuracy: 0.597 [after 131 batches]\n",
            "val loss: 0.746 accuracy: 0.667 [after 30 batches]\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "train loss: 0.692 accuracy: 0.553 [after 32 batches]\n",
            "train loss: 0.691 accuracy: 0.509 [after 65 batches]\n",
            "train loss: 0.694 accuracy: 0.504 [after 98 batches]\n",
            "train loss: 0.686 accuracy: 0.528 [after 131 batches]\n",
            "val loss: 0.651 accuracy: 0.671 [after 30 batches]\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "train loss: 0.700 accuracy: 0.561 [after 32 batches]\n",
            "train loss: 0.701 accuracy: 0.545 [after 65 batches]\n",
            "train loss: 0.697 accuracy: 0.554 [after 98 batches]\n",
            "train loss: 0.692 accuracy: 0.560 [after 131 batches]\n",
            "val loss: 0.777 accuracy: 0.667 [after 30 batches]\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "train loss: 0.692 accuracy: 0.557 [after 32 batches]\n",
            "train loss: 0.692 accuracy: 0.559 [after 65 batches]\n",
            "train loss: 0.687 accuracy: 0.578 [after 98 batches]\n",
            "train loss: 0.689 accuracy: 0.560 [after 131 batches]\n",
            "val loss: 0.654 accuracy: 0.704 [after 30 batches]\n",
            "test accuracy: 0.714 recall: 0.838 precision: 0.655 f1: 0.709 [after 28 batches]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch ▁▂▃▄▅▅▆▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy ▂▂▃▂▁▅▄▃▂▂▃▃▆▇▆▆█▆▆▅█▇▇▇▅▃▂▄▅▅▅▅▅▅▆▅\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss █▆▅▄▃▂▃▃▂▂▂▂▁▂▂▁▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy ▁▆▂█▆▇▇▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss ▅▆▆▁▃▇▂█▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          epoch 9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           step 35\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  test_accuracy 0.71429\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        test_f1 0.70928\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: test_precision 0.65476\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    test_recall 0.8375\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train_accuracy 0.55966\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     train_loss 0.68917\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val_accuracy 0.70417\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       val_loss 0.65405\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdandy-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/psadoyj7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240609_183633-psadoyj7/logs\u001b[0m\n",
            "2024-06-09 18:49:35,592 - wandb.wandb_agent - INFO - Cleaning up finished run: psadoyj7\n",
            "2024-06-09 18:49:36,026 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2024-06-09 18:49:36,026 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\tarchitecture: xception\n",
            "\taugmented: True\n",
            "\tbatch_size: 55\n",
            "\tfold: 6\n",
            "\tlearning_rate: 0.0012656963553523929\n",
            "\tnormalize: True\n",
            "\toptimizer: sgd\n",
            "\tresize: 50\n",
            "2024-06-09 18:49:36,028 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train_one_run.py --architecture=xception --augmented=True --batch_size=55 --fold=6 --learning_rate=0.0012656963553523929 --normalize=True --optimizer=sgd --resize=50\n",
            "2024-06-09 18:49:41,037 - wandb.wandb_agent - INFO - Running runs: ['qb6bpq52']\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgpintoruiz\u001b[0m (\u001b[33maiuis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/Thermal-Imaging-Breast-Cancer-Detection/notebooks/wandb/run-20240609_184942-qb6bpq52\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mwise-sweep-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/sweeps/epbt9jh6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aiuis/dip-project/runs/qb6bpq52\u001b[0m\n",
            "FOLD 6\n",
            "-------------------------------\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "train loss: 0.684 accuracy: 0.531 [after 4 batches]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}